{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 : Data Preparation and Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install required and/or update third-party libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/secretstorage/dhcrypto.py:16: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "/opt/conda/lib/python3.7/site-packages/secretstorage/util.py:25: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "/opt/conda/lib/python3.7/site-packages/secretstorage/dhcrypto.py:16: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "/opt/conda/lib/python3.7/site-packages/secretstorage/util.py:25: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install -Uq pip\n",
    "!python -m pip install -Uq sagemaker boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading stored variables\n",
    "If you ran this notebook before, you may want to re-use the resources you aready created with AWS. Run the cell below to load any prevously created variables. You should see a print-out of the existing variables. If you don't see anything printed then it's probably the first time you are running the notebook!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored variables and their in-db values:\n"
     ]
    }
   ],
   "source": [
    "%store -r\n",
    "%store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ": You must have run the previous sequential notebooks to retrieve variables using the StoreMagic command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 01\n",
    "import sagemaker\n",
    "bucket=sagemaker.Session().default_bucket()\n",
    "prefix = 'sagemaker/DEMO-xgboost-tripfare'\n",
    " \n",
    "# Define IAM role\n",
    "import boto3\n",
    "import re\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 02\n",
    "import numpy as np                                # For matrix operations and numerical processing\n",
    "import pandas as pd                               # For munging tabular data\n",
    "import matplotlib.pyplot as plt                   # For charts and visualizations\n",
    "from IPython.display import Image                 # For displaying images in the notebook\n",
    "from IPython.display import display               # For displaying outputs in the notebook\n",
    "from time import gmtime, strftime                 # For labeling SageMaker models, endpoints, etc.\n",
    "import sys                                        # For writing outputs to notebook\n",
    "import math                                       # For ceiling function\n",
    "import json                                       # For parsing hosting outputs\n",
    "import os                                         # For manipulating filepath names\n",
    "import sagemaker \n",
    "import zipfile     # Amazon SageMaker's Python SDK provides many helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-631450739534/sagemaker/DEMO-xgboost-tripfare/input/'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_source = f's3://{bucket}/{prefix}/input/'\n",
    "input_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = input_source + 'data/'\n",
    "input_zones = input_source + 'zones/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copy: s3://nyc-tlc/trip data/green_tripdata_2018-10.csv to s3://sagemaker-us-east-1-631450739534/sagemaker/DEMO-xgboost-tripfare/input/data/green_tripdata_2018-10.csv\n",
      "copy: s3://nyc-tlc/trip data/green_tripdata_2018-11.csv to s3://sagemaker-us-east-1-631450739534/sagemaker/DEMO-xgboost-tripfare/input/data/green_tripdata_2018-11.csv\n",
      "copy: s3://nyc-tlc/trip data/green_tripdata_2018-12.csv to s3://sagemaker-us-east-1-631450739534/sagemaker/DEMO-xgboost-tripfare/input/data/green_tripdata_2018-12.csv\n",
      "copy: s3://nyc-tlc/misc/taxi_zones.zip to s3://sagemaker-us-east-1-631450739534/sagemaker/DEMO-xgboost-tripfare/input/zones/taxi_zones.zip\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp --recursive 's3://nyc-tlc/trip data/' $input_data --exclude '*' --include 'green_tripdata_2018-1*'\n",
    "# !aws s3 cp 's3://nyc-tlc/trip data/green_tripdata_2018-02.csv' $input_data\n",
    "!aws s3 cp 's3://nyc-tlc/misc/taxi_zones.zip' $input_zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-30 01:59:14   63666398 green_tripdata_2018-10.csv\n",
      "2021-09-30 01:59:14   58812608 green_tripdata_2018-11.csv\n",
      "2021-09-30 01:59:14   61371115 green_tripdata_2018-12.csv\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls $input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 05\n",
    "from sagemaker import Session\n",
    "\n",
    "sess = Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting preprocess.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile preprocess.py\n",
    "\n",
    "import glob\n",
    "import logging\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "from zipfile import ZipFile\n",
    "# from time import gmtime, strftime\n",
    "import socket\n",
    "import shutil\n",
    "import json\n",
    "\n",
    "host_name = socket.gethostname()\n",
    "print(host_name)\n",
    "print(os.environ)\n",
    "\n",
    "# Install geopandas dependency before including pandas\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"geopandas==0.9.0\"])\n",
    "\n",
    "import pandas as pd  # noqa: E402\n",
    "import geopandas as gpd  # noqa: E402\n",
    "from sklearn.model_selection import train_test_split  # noqa: E402\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "logger.addHandler(logging.StreamHandler())\n",
    "\n",
    "\n",
    "def extract_zones(zones_file: str, zones_dir: str):\n",
    "    logger.info(f\"Extracting zone file: {zones_file}\")\n",
    "    with ZipFile(zones_file, \"r\") as zip:\n",
    "        zip.extractall(zones_dir)\n",
    "\n",
    "\n",
    "def load_zones(zones_dir: str):\n",
    "    logging.info(f\"Loading zones from {zones_dir}\")\n",
    "    # Load the shape file and get the geometry and lat/lon\n",
    "    zone_df = gpd.read_file(os.path.join(zones_dir, \"taxi_zones.shp\"))\n",
    "    # Get centroids as EPSG code of 3310 to measure distance\n",
    "    zone_df[\"centroid\"] = zone_df.geometry.centroid.to_crs(epsg=3310)\n",
    "    # Convert cordinates to the WSG84 lat/long CRS has a EPSG code of 4326.\n",
    "    zone_df[\"latitude\"] = zone_df.centroid.to_crs(epsg=4326).x\n",
    "    zone_df[\"longitude\"] = zone_df.centroid.to_crs(epsg=4326).y\n",
    "    return zone_df\n",
    "\n",
    "\n",
    "def load_data(file_list: list):\n",
    "    # Define dates, and columns to use\n",
    "    use_cols = [\n",
    "        \"fare_amount\",\n",
    "        \"lpep_pickup_datetime\",\n",
    "        \"lpep_dropoff_datetime\",\n",
    "        \"passenger_count\",\n",
    "        \"PULocationID\",\n",
    "        \"DOLocationID\",\n",
    "    ]\n",
    "    # Concat input files with select columns\n",
    "    dfs = []\n",
    "    for file in file_list:\n",
    "        dfs.append(pd.read_csv(file, usecols=use_cols))\n",
    "    return pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "\n",
    "def enrich_data(trip_df: pd.DataFrame, zone_df: pd.DataFrame):\n",
    "    # Join trip DF to zones for poth pickup and drop off locations\n",
    "    trip_df = gpd.GeoDataFrame(\n",
    "        trip_df.join(zone_df, on=\"PULocationID\").join(\n",
    "            zone_df, on=\"DOLocationID\", rsuffix=\"_DO\", lsuffix=\"_PU\"\n",
    "        )\n",
    "    )\n",
    "    trip_df[\"geo_distance\"] = (\n",
    "        trip_df[\"centroid_PU\"].distance(trip_df[\"centroid_DO\"]) / 1000\n",
    "    )\n",
    "\n",
    "    # Add date parts\n",
    "    trip_df[\"lpep_pickup_datetime\"] = pd.to_datetime(trip_df[\"lpep_pickup_datetime\"])\n",
    "    trip_df[\"hour\"] = trip_df[\"lpep_pickup_datetime\"].dt.hour\n",
    "    trip_df[\"weekday\"] = trip_df[\"lpep_pickup_datetime\"].dt.weekday\n",
    "    trip_df[\"month\"] = trip_df[\"lpep_pickup_datetime\"].dt.month\n",
    "\n",
    "    # Get calculated duration in minutes\n",
    "    trip_df[\"lpep_dropoff_datetime\"] = pd.to_datetime(trip_df[\"lpep_dropoff_datetime\"])\n",
    "    trip_df[\"duration_minutes\"] = (\n",
    "        trip_df[\"lpep_dropoff_datetime\"] - trip_df[\"lpep_pickup_datetime\"]\n",
    "    ).dt.seconds / 60\n",
    "\n",
    "    # Rename and filter cols\n",
    "    trip_df = trip_df.rename(\n",
    "        columns={\n",
    "            \"latitude_PU\": \"pickup_latitude\",\n",
    "            \"longitude_PU\": \"pickup_longitude\",\n",
    "            \"latitude_DO\": \"dropoff_latitude\",\n",
    "            \"longitude_DO\": \"dropoff_longitude\",\n",
    "        }\n",
    "    )\n",
    "    return trip_df\n",
    "\n",
    "\n",
    "def clean_data(trip_df: pd.DataFrame):\n",
    "    # Remove outliers\n",
    "    trip_df = trip_df[\n",
    "        (trip_df.fare_amount > 0)\n",
    "        & (trip_df.fare_amount < 200)\n",
    "        & (trip_df.passenger_count > 0)\n",
    "        & (trip_df.duration_minutes > 0)\n",
    "        & (trip_df.duration_minutes < 120)\n",
    "        & (trip_df.geo_distance > 0)\n",
    "        & (trip_df.geo_distance < 121)\n",
    "    ].dropna()\n",
    "\n",
    "    # Filter columns\n",
    "    cols = [\n",
    "        \"fare_amount\",\n",
    "        \"passenger_count\",\n",
    "        \"pickup_latitude\",\n",
    "        \"pickup_longitude\",\n",
    "        \"dropoff_latitude\",\n",
    "        \"dropoff_longitude\",\n",
    "        \"geo_distance\",\n",
    "        \"hour\",\n",
    "        \"weekday\",\n",
    "        \"month\",\n",
    "    ]\n",
    "    return trip_df[cols]\n",
    "\n",
    "\n",
    "def save_files(base_dir: str, data_df: pd.DataFrame, val_size=0.2, test_size=0.05, current_host=None):\n",
    "        \n",
    "    logger.info(f\"Splitting {len(data_df)} rows of data into train, val, test.\")\n",
    "    train_df, val_df = train_test_split(data_df, test_size=val_size, random_state=42)\n",
    "    val_df, test_df = train_test_split(val_df, test_size=test_size, random_state=42)\n",
    "\n",
    "    logger.info(f\"Writing out datasets to {base_dir}\")\n",
    "    train_df.to_csv(f\"{base_dir}/train/train-{current_host}.csv\", header=False, index=False)\n",
    "    val_df.to_csv(f\"{base_dir}/validation/validation-{current_host}.csv\", header=False, index=False)\n",
    "\n",
    "    # Save test data without header\n",
    "    test_df.to_csv(f\"{base_dir}/test/test-{current_host}.csv\", header=False, index=False)\n",
    "\n",
    "    return train_df, val_df, test_df\n",
    "\n",
    "def _read_json(path):  # type: (str) -> dict\n",
    "    \"\"\"Read a JSON file.\n",
    "    Args:\n",
    "        path (str): Path to the file.\n",
    "    Returns:\n",
    "        (dict[object, object]): A dictionary representation of the JSON file.\n",
    "    \"\"\"\n",
    "    with open(path, \"r\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def main(base_dir):\n",
    "    # Input data files\n",
    "    input_dir = os.path.join(base_dir, \"input/data\")\n",
    "    input_file_list = glob.glob(f\"{input_dir}/*.csv\")\n",
    "    logger.info(f\"Input file list: {input_file_list}\")\n",
    "    \n",
    "    config_file_list = glob.glob(\"/opt/ml/config/*.json\")\n",
    "    logger.info(f\"config file list: {config_file_list}\")\n",
    "    if \"/opt/ml/config/resourceconfig.json\" in config_file_list:\n",
    "        hosts = _read_json(\"/opt/ml/config/resourceconfig.json\")\n",
    "        logger.info(hosts)\n",
    "        current_host = hosts[\"current_host\"]\n",
    "        logger.info(current_host)\n",
    "    else:\n",
    "        current_host = 'algo-0'\n",
    "        \n",
    "    if len(input_file_list) == 0:\n",
    "        raise Exception(f\"No input files found in {input_dir}\")\n",
    "\n",
    "    # Input zones file\n",
    "    zones_dir = os.path.join(base_dir, \"input/zones\")\n",
    "    zones_file = os.path.join(zones_dir, \"taxi_zones.zip\")\n",
    "    if not os.path.exists(zones_file):\n",
    "        raise Exception(f\"Zones file {zones_file} does not exist\")\n",
    "\n",
    "    # Extract and load taxi zones geopandas dataframe\n",
    "    extract_zones(zones_file, zones_dir)\n",
    "    zone_df = load_zones(zones_dir)\n",
    "\n",
    "    # Load input files\n",
    "    data_df = load_data(input_file_list)\n",
    "    data_df = enrich_data(data_df, zone_df)\n",
    "    data_df = clean_data(data_df)\n",
    "    return save_files(base_dir, data_df, current_host=current_host)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    logger.info(\"Starting preprocessing.\")\n",
    "    main(\"/opt/ml/processing\")\n",
    "    logger.info(\"Done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 07\n",
    "train_path = f\"s3://{bucket}/{prefix}/train\"\n",
    "validation_path = f\"s3://{bucket}/{prefix}/validation\"\n",
    "test_path = f\"s3://{bucket}/{prefix}/test\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Name:  sm-immday-skprocessing-2021-09-30-04-46-49-652\n",
      "Inputs:  [{'InputName': 'input-1', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-631450739534/sagemaker/DEMO-xgboost-tripfare/input/data/', 'LocalPath': '/opt/ml/processing/input/data', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'ShardedByS3Key', 'S3CompressionType': 'None'}}, {'InputName': 'input-2', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-631450739534/sagemaker/DEMO-xgboost-tripfare/input/zones/', 'LocalPath': '/opt/ml/processing/input/zones', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'code', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-631450739534/sm-immday-skprocessing-2021-09-30-04-46-49-652/input/code/preprocess.py', 'LocalPath': '/opt/ml/processing/input/code', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}]\n",
      "Outputs:  [{'OutputName': 'train', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-631450739534/sagemaker/DEMO-xgboost-tripfare/train', 'LocalPath': '/opt/ml/processing/train', 'S3UploadMode': 'EndOfJob'}}, {'OutputName': 'validation', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-631450739534/sagemaker/DEMO-xgboost-tripfare/validation', 'LocalPath': '/opt/ml/processing/validation', 'S3UploadMode': 'EndOfJob'}}, {'OutputName': 'test', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-631450739534/sagemaker/DEMO-xgboost-tripfare/test', 'LocalPath': '/opt/ml/processing/test', 'S3UploadMode': 'EndOfJob'}}]\n",
      "............................\u001b[34mip-10-0-179-185.ec2.internal\u001b[0m\n",
      "\u001b[34menviron({'PATH': '/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin', 'HOSTNAME': 'ip-10-0-179-185.ec2.internal', 'AWS_REGION': 'us-east-1', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/nxwrOLCLrWdO1bzzYn6oGTNn0OfOOGlGSak4VLME1zk', 'PYTHONDONTWRITEBYTECODE': '1', 'PYTHONUNBUFFERED': '1', 'PYTHONIOENCODING': 'UTF-8', 'LANG': 'C.UTF-8', 'LC_ALL': 'C.UTF-8', 'SAGEMAKER_SKLEARN_VERSION': '0.23-1', 'SAGEMAKER_TRAINING_MODULE': 'sagemaker_sklearn_container.training:main', 'SAGEMAKER_SERVING_MODULE': 'sagemaker_sklearn_container.serving:main', 'SKLEARN_MMS_CONFIG': '/home/model-server/config.properties', 'SM_INPUT': '/opt/ml/input', 'SM_INPUT_TRAINING_CONFIG_FILE': '/opt/ml/input/config/hyperparameters.json', 'SM_INPUT_DATA_CONFIG_FILE': '/opt/ml/input/config/inputdataconfig.json', 'SM_CHECKPOINT_CONFIG_FILE': '/opt/ml/input/config/checkpointconfig.json', 'SM_MODEL_DIR': '/opt/ml/model', 'TEMP': '/home/model-server/tmp', 'HOME': '/root'})\u001b[0m\n",
      "\u001b[34mCollecting geopandas==0.9.0\n",
      "  Downloading geopandas-0.9.0-py2.py3-none-any.whl (994 kB)\u001b[0m\n",
      "\u001b[34mCollecting shapely>=1.6\n",
      "  Downloading Shapely-1.7.1-cp37-cp37m-manylinux1_x86_64.whl (1.0 MB)\u001b[0m\n",
      "\u001b[34mCollecting pyproj>=2.2.0\n",
      "  Downloading pyproj-3.2.1-cp37-cp37m-manylinux2010_x86_64.whl (6.3 MB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas>=0.24.0 in /miniconda3/lib/python3.7/site-packages (from geopandas==0.9.0) (1.1.3)\u001b[0m\n",
      "\u001b[34mCollecting fiona>=1.8\n",
      "  Downloading Fiona-1.8.20-cp37-cp37m-manylinux1_x86_64.whl (15.4 MB)\u001b[0m\n",
      "\u001b[34mCollecting cligj>=0.5\n",
      "  Downloading cligj-0.7.2-py3-none-any.whl (7.1 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six>=1.7 in /miniconda3/lib/python3.7/site-packages (from fiona>=1.8->geopandas==0.9.0) (1.15.0)\u001b[0m\n",
      "\u001b[34mCollecting click-plugins>=1.0\n",
      "  Downloading click_plugins-1.1.1-py2.py3-none-any.whl (7.5 kB)\u001b[0m\n",
      "\u001b[34mCollecting munch\n",
      "  Downloading munch-2.5.0-py2.py3-none-any.whl (10 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: click>=4.0 in /miniconda3/lib/python3.7/site-packages (from fiona>=1.8->geopandas==0.9.0) (8.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: setuptools in /miniconda3/lib/python3.7/site-packages (from fiona>=1.8->geopandas==0.9.0) (52.0.0.post20210125)\u001b[0m\n",
      "\u001b[34mCollecting attrs>=17\n",
      "  Downloading attrs-21.2.0-py2.py3-none-any.whl (53 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi in /miniconda3/lib/python3.7/site-packages (from fiona>=1.8->geopandas==0.9.0) (2021.5.30)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: importlib-metadata in /miniconda3/lib/python3.7/site-packages (from click>=4.0->fiona>=1.8->geopandas==0.9.0) (4.7.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2017.2 in /miniconda3/lib/python3.7/site-packages (from pandas>=0.24.0->geopandas==0.9.0) (2021.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.7.3 in /miniconda3/lib/python3.7/site-packages (from pandas>=0.24.0->geopandas==0.9.0) (2.8.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.15.4 in /miniconda3/lib/python3.7/site-packages (from pandas>=0.24.0->geopandas==0.9.0) (1.19.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: zipp>=0.5 in /miniconda3/lib/python3.7/site-packages (from importlib-metadata->click>=4.0->fiona>=1.8->geopandas==0.9.0) (3.5.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions>=3.6.4 in /miniconda3/lib/python3.7/site-packages (from importlib-metadata->click>=4.0->fiona>=1.8->geopandas==0.9.0) (3.10.0.0)\u001b[0m\n",
      "\u001b[34mInstalling collected packages: munch, cligj, click-plugins, attrs, shapely, pyproj, fiona, geopandas\u001b[0m\n",
      "\u001b[35mip-10-0-184-98.ec2.internal\u001b[0m\n",
      "\u001b[35menviron({'PATH': '/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin', 'HOSTNAME': 'ip-10-0-184-98.ec2.internal', 'AWS_REGION': 'us-east-1', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/nxwrOLCLrWdO1bzzYn6oGTNn0OfOOGlGSak4VLME1zk', 'PYTHONDONTWRITEBYTECODE': '1', 'PYTHONUNBUFFERED': '1', 'PYTHONIOENCODING': 'UTF-8', 'LANG': 'C.UTF-8', 'LC_ALL': 'C.UTF-8', 'SAGEMAKER_SKLEARN_VERSION': '0.23-1', 'SAGEMAKER_TRAINING_MODULE': 'sagemaker_sklearn_container.training:main', 'SAGEMAKER_SERVING_MODULE': 'sagemaker_sklearn_container.serving:main', 'SKLEARN_MMS_CONFIG': '/home/model-server/config.properties', 'SM_INPUT': '/opt/ml/input', 'SM_INPUT_TRAINING_CONFIG_FILE': '/opt/ml/input/config/hyperparameters.json', 'SM_INPUT_DATA_CONFIG_FILE': '/opt/ml/input/config/inputdataconfig.json', 'SM_CHECKPOINT_CONFIG_FILE': '/opt/ml/input/config/checkpointconfig.json', 'SM_MODEL_DIR': '/opt/ml/model', 'TEMP': '/home/model-server/tmp', 'HOME': '/root'})\u001b[0m\n",
      "\u001b[35mCollecting geopandas==0.9.0\n",
      "  Downloading geopandas-0.9.0-py2.py3-none-any.whl (994 kB)\u001b[0m\n",
      "\u001b[35mCollecting shapely>=1.6\n",
      "  Downloading Shapely-1.7.1-cp37-cp37m-manylinux1_x86_64.whl (1.0 MB)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: pandas>=0.24.0 in /miniconda3/lib/python3.7/site-packages (from geopandas==0.9.0) (1.1.3)\u001b[0m\n",
      "\u001b[35mCollecting pyproj>=2.2.0\n",
      "  Downloading pyproj-3.2.1-cp37-cp37m-manylinux2010_x86_64.whl (6.3 MB)\u001b[0m\n",
      "\u001b[35mCollecting fiona>=1.8\n",
      "  Downloading Fiona-1.8.20-cp37-cp37m-manylinux1_x86_64.whl (15.4 MB)\u001b[0m\n",
      "\u001b[35mCollecting attrs>=17\n",
      "  Downloading attrs-21.2.0-py2.py3-none-any.whl (53 kB)\u001b[0m\n",
      "\u001b[35mCollecting cligj>=0.5\n",
      "  Downloading cligj-0.7.2-py3-none-any.whl (7.1 kB)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: click>=4.0 in /miniconda3/lib/python3.7/site-packages (from fiona>=1.8->geopandas==0.9.0) (8.0.1)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: setuptools in /miniconda3/lib/python3.7/site-packages (from fiona>=1.8->geopandas==0.9.0) (52.0.0.post20210125)\u001b[0m\n",
      "\u001b[35mCollecting munch\n",
      "  Downloading munch-2.5.0-py2.py3-none-any.whl (10 kB)\u001b[0m\n",
      "\u001b[35mCollecting click-plugins>=1.0\n",
      "  Downloading click_plugins-1.1.1-py2.py3-none-any.whl (7.5 kB)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: six>=1.7 in /miniconda3/lib/python3.7/site-packages (from fiona>=1.8->geopandas==0.9.0) (1.15.0)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: certifi in /miniconda3/lib/python3.7/site-packages (from fiona>=1.8->geopandas==0.9.0) (2021.5.30)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: importlib-metadata in /miniconda3/lib/python3.7/site-packages (from click>=4.0->fiona>=1.8->geopandas==0.9.0) (4.7.1)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: pytz>=2017.2 in /miniconda3/lib/python3.7/site-packages (from pandas>=0.24.0->geopandas==0.9.0) (2021.1)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: numpy>=1.15.4 in /miniconda3/lib/python3.7/site-packages (from pandas>=0.24.0->geopandas==0.9.0) (1.19.2)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: python-dateutil>=2.7.3 in /miniconda3/lib/python3.7/site-packages (from pandas>=0.24.0->geopandas==0.9.0) (2.8.1)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: typing-extensions>=3.6.4 in /miniconda3/lib/python3.7/site-packages (from importlib-metadata->click>=4.0->fiona>=1.8->geopandas==0.9.0) (3.10.0.0)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: zipp>=0.5 in /miniconda3/lib/python3.7/site-packages (from importlib-metadata->click>=4.0->fiona>=1.8->geopandas==0.9.0) (3.5.0)\u001b[0m\n",
      "\u001b[35mInstalling collected packages: munch, cligj, click-plugins, attrs, shapely, pyproj, fiona, geopandas\u001b[0m\n",
      "\u001b[34mSuccessfully installed attrs-21.2.0 click-plugins-1.1.1 cligj-0.7.2 fiona-1.8.20 geopandas-0.9.0 munch-2.5.0 pyproj-3.2.1 shapely-1.7.1\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[35mSuccessfully installed attrs-21.2.0 click-plugins-1.1.1 cligj-0.7.2 fiona-1.8.20 geopandas-0.9.0 munch-2.5.0 pyproj-3.2.1 shapely-1.7.1\u001b[0m\n",
      "\u001b[35mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34mStarting preprocessing.\u001b[0m\n",
      "\u001b[34mInput file list: ['/opt/ml/processing/input/data/green_tripdata_2018-10.csv', '/opt/ml/processing/input/data/green_tripdata_2018-12.csv']\u001b[0m\n",
      "\u001b[34mconfig file list: ['/opt/ml/config/processingjobconfig.json', '/opt/ml/config/resourceconfig.json']\u001b[0m\n",
      "\u001b[34m{'current_host': 'algo-1', 'hosts': ['algo-1', 'algo-2']}\u001b[0m\n",
      "\u001b[34malgo-1\u001b[0m\n",
      "\u001b[34malgo-1\u001b[0m\n",
      "\u001b[34mExtracting zone file: /opt/ml/processing/input/zones/taxi_zones.zip\u001b[0m\n",
      "\u001b[34mLoading zones from /opt/ml/processing/input/zones\u001b[0m\n",
      "\u001b[35mStarting preprocessing.\u001b[0m\n",
      "\u001b[35mInput file list: ['/opt/ml/processing/input/data/green_tripdata_2018-11.csv']\u001b[0m\n",
      "\u001b[35mconfig file list: ['/opt/ml/config/processingjobconfig.json', '/opt/ml/config/resourceconfig.json']\u001b[0m\n",
      "\u001b[35m{'current_host': 'algo-2', 'hosts': ['algo-1', 'algo-2']}\u001b[0m\n",
      "\u001b[35malgo-2\u001b[0m\n",
      "\u001b[35malgo-2\u001b[0m\n",
      "\u001b[35mExtracting zone file: /opt/ml/processing/input/zones/taxi_zones.zip\u001b[0m\n",
      "\u001b[35mLoading zones from /opt/ml/processing/input/zones\u001b[0m\n",
      "\u001b[35mSplitting 551424 rows of data into train, val, test.\u001b[0m\n",
      "\u001b[35mWriting out datasets to /opt/ml/processing\u001b[0m\n",
      "\u001b[35mDone\u001b[0m\n",
      "\u001b[34mSplitting 1176620 rows of data into train, val, test.\u001b[0m\n",
      "\u001b[34mWriting out datasets to /opt/ml/processing\u001b[0m\n",
      "\u001b[34mDone\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# cell 08\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "\n",
    "sklearn_processor = SKLearnProcessor(\n",
    "    framework_version=\"0.23-1\",\n",
    "    role=get_execution_role(),\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    instance_count=2, \n",
    "    base_job_name='sm-immday-skprocessing'\n",
    ")\n",
    "\n",
    "sklearn_processor.run(\n",
    "    code='preprocess.py',\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source=input_data,\n",
    "            destination=\"/opt/ml/processing/input/data\",\n",
    "            s3_data_distribution_type=\"ShardedByS3Key\",\n",
    "        ),\n",
    "        ProcessingInput(\n",
    "            source=input_zones,\n",
    "            destination=\"/opt/ml/processing/input/zones\",\n",
    "            s3_data_distribution_type=\"FullyReplicated\",\n",
    "        ),\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"train\", source=\"/opt/ml/processing/train\", destination=train_path),\n",
    "        ProcessingOutput(output_name=\"validation\", source=\"/opt/ml/processing/validation\", destination=validation_path),\n",
    "        ProcessingOutput(output_name=\"test\", source=\"/opt/ml/processing/test\", destination=test_path),\n",
    "    ]\n",
    "        \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'train_path' (str)\n",
      "Stored 'validation_path' (str)\n",
      "Stored 'test_path' (str)\n"
     ]
    }
   ],
   "source": [
    "%store train_path\n",
    "%store validation_path\n",
    "%store test_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
