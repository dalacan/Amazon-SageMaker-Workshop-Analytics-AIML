{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 : Data Preparation and Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install required and/or update third-party libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/secretstorage/dhcrypto.py:16: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "/opt/conda/lib/python3.7/site-packages/secretstorage/util.py:25: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "/opt/conda/lib/python3.7/site-packages/secretstorage/dhcrypto.py:16: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "/opt/conda/lib/python3.7/site-packages/secretstorage/util.py:25: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install -Uq pip\n",
    "!python -m pip install -Uq sagemaker boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading stored variables\n",
    "If you ran this notebook before, you may want to re-use the resources you aready created with AWS. Run the cell below to load any prevously created variables. You should see a print-out of the existing variables. If you don't see anything printed then it's probably the first time you are running the notebook!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored variables and their in-db values:\n",
      "base_uri                      -> 's3://sagemaker-us-east-1-631450739534/abalone'\n",
      "batch_data_uri                -> 's3://sagemaker-us-east-1-631450739534/abalone/aba\n",
      "input_data                    -> 's3://sagemaker-us-east-1-631450739534/sagemaker/D\n",
      "input_data_uri                -> 's3://sagemaker-us-east-1-631450739534/abalone/aba\n",
      "input_zones                   -> 's3://sagemaker-us-east-1-631450739534/sagemaker/D\n",
      "local_path                    -> 'data/abalone-dataset.csv'\n",
      "model_url                     -> 's3://sagemaker-us-east-1-631450739534/sagemaker/D\n",
      "process_script                -> '/root/Amazon-SageMaker-Workshop-Custom/preprocess\n",
      "test_path                     -> 's3://sagemaker-us-east-1-631450739534/sagemaker/D\n",
      "train_path                    -> 's3://sagemaker-us-east-1-631450739534/sagemaker/D\n",
      "training_job_name             -> 'DEMO-xgboost-tripfare-train-2021-09-30-03-08-58-4\n",
      "validation_path               -> 's3://sagemaker-us-east-1-631450739534/sagemaker/D\n"
     ]
    }
   ],
   "source": [
    "%store -r\n",
    "%store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ": You must have run the previous sequential notebooks to retrieve variables using the StoreMagic command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 01\n",
    "import sagemaker\n",
    "bucket=sagemaker.Session().default_bucket()\n",
    "prefix = 'sagemaker/DEMO-xgboost-tripfare'\n",
    " \n",
    "# Define IAM role\n",
    "import boto3\n",
    "import re\n",
    "import os\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 02\n",
    "import numpy as np                                # For matrix operations and numerical processing\n",
    "import pandas as pd                               # For munging tabular data\n",
    "import matplotlib.pyplot as plt                   # For charts and visualizations\n",
    "from IPython.display import Image                 # For displaying images in the notebook\n",
    "from IPython.display import display               # For displaying outputs in the notebook\n",
    "from time import gmtime, strftime                 # For labeling SageMaker models, endpoints, etc.\n",
    "import sys                                        # For writing outputs to notebook\n",
    "import math                                       # For ceiling function\n",
    "import json                                       # For parsing hosting outputs\n",
    "import os                                         # For manipulating filepath names\n",
    "import sagemaker \n",
    "import zipfile     # Amazon SageMaker's Python SDK provides many helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.59.5'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sagemaker.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-631450739534/sagemaker/DEMO-xgboost-tripfare/input/'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_source = f's3://{bucket}/{prefix}/input/'\n",
    "input_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = input_source + 'data/'\n",
    "input_zones = input_source + 'zones/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'input_data' (str)\n",
      "Stored 'input_zones' (str)\n"
     ]
    }
   ],
   "source": [
    "%store input_data\n",
    "%store input_zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copy: s3://nyc-tlc/trip data/green_tripdata_2018-10.csv to s3://sagemaker-us-east-1-631450739534/sagemaker/DEMO-xgboost-tripfare/input/data/green_tripdata_2018-10.csv\n",
      "copy: s3://nyc-tlc/trip data/green_tripdata_2018-12.csv to s3://sagemaker-us-east-1-631450739534/sagemaker/DEMO-xgboost-tripfare/input/data/green_tripdata_2018-12.csv\n",
      "copy: s3://nyc-tlc/trip data/green_tripdata_2018-11.csv to s3://sagemaker-us-east-1-631450739534/sagemaker/DEMO-xgboost-tripfare/input/data/green_tripdata_2018-11.csv\n",
      "copy: s3://nyc-tlc/misc/taxi_zones.zip to s3://sagemaker-us-east-1-631450739534/sagemaker/DEMO-xgboost-tripfare/input/zones/taxi_zones.zip\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp --recursive 's3://nyc-tlc/trip data/' $input_data --exclude '*' --include 'green_tripdata_2018-1*'\n",
    "# !aws s3 cp 's3://nyc-tlc/trip data/green_tripdata_2018-02.csv' $input_data\n",
    "!aws s3 cp 's3://nyc-tlc/misc/taxi_zones.zip' $input_zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-06 02:42:53   63666398 green_tripdata_2018-10.csv\n",
      "2021-10-06 02:42:53   58812608 green_tripdata_2018-11.csv\n",
      "2021-10-06 02:42:53   61371115 green_tripdata_2018-12.csv\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls $input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 05\n",
    "from sagemaker import Session\n",
    "\n",
    "sess = Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Feature Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-us-east-1-631450739534/sagemaker/DEMO-xgboost-tripfare/train/train-algo-1.csv to ./train-algo-1.csv\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp $train_path/train-algo-1.csv ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train-algo-1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.5                   float64\n",
       "1                       int64\n",
       "-73.94575022751276    float64\n",
       "40.790010676294       float64\n",
       "-73.90512246226346    float64\n",
       "40.84905828506662     float64\n",
       "7.397563308633733     float64\n",
       "8                       int64\n",
       "3                       int64\n",
       "12                      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_schemas = [\n",
    "    {\n",
    "        \"name\": \"fare_amount\",\n",
    "        \"type\": \"float\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"passenger_count\",\n",
    "        \"type\": \"long\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"pickup_latitude\",\n",
    "        \"type\": \"float\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"pickup_longitude\",\n",
    "        \"type\": \"float\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"dropoff_latitude\",\n",
    "        \"type\": \"float\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"dropoff_longitude\",\n",
    "        \"type\": \"float\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"geo_distance\",\n",
    "        \"type\": \"float\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"hour\",\n",
    "        \"type\": \"int\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"weekday\",\n",
    "        \"type\": \"int\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"month\",\n",
    "        \"type\": \"int\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"FS_ID\",\n",
    "        \"type\": \"long\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"FS_time\",\n",
    "        \"type\": \"float\"\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.feature_store.feature_definition import FeatureDefinition\n",
    "from sagemaker.feature_store.feature_definition import FeatureTypeEnum\n",
    "\n",
    "default_feature_type = FeatureTypeEnum.STRING\n",
    "column_to_feature_type_mapping = {\n",
    "    \"float\": FeatureTypeEnum.FRACTIONAL,\n",
    "    \"long\": FeatureTypeEnum.INTEGRAL\n",
    "}\n",
    "\n",
    "feature_definitions = [\n",
    "    FeatureDefinition(\n",
    "        feature_name=column_schema['name'], \n",
    "        feature_type=column_to_feature_type_mapping.get(column_schema['type'], default_feature_type)\n",
    "    ) for column_schema in column_schemas\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize & Create Feature Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "region = boto3.Session().region_name\n",
    "boto_session = boto3.Session(region_name=region)\n",
    "\n",
    "sagemaker_client = boto_session.client(service_name='sagemaker', region_name=region)\n",
    "featurestore_runtime = boto_session.client(service_name='sagemaker-featurestore-runtime', region_name=region)\n",
    "\n",
    "feature_store_session = sagemaker.session.Session(\n",
    "    boto_session=boto_session,\n",
    "    sagemaker_client=sagemaker_client,\n",
    "    sagemaker_featurestore_runtime_client=featurestore_runtime\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'tripfare_feature_group_name' (str)\n",
      "Customers feature group name = fscw-tripfare-10-06-06-01\n"
     ]
    }
   ],
   "source": [
    "current_timestamp = strftime('%m-%d-%H-%M', gmtime())\n",
    "\n",
    "# prefix to track all the feature groups created as part of feature store champions workshop (fscw)\n",
    "fs_prefix = 'fscw-'\n",
    "\n",
    "tripfare_feature_group_name = f'{fs_prefix}tripfare-{current_timestamp}'\n",
    "%store tripfare_feature_group_name\n",
    "\n",
    "print(f'Customers feature group name = {tripfare_feature_group_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature group is initialized and created below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FeatureGroupArn': 'arn:aws:sagemaker:us-east-1:631450739534:feature-group/fscw-tripfare-10-06-06-01',\n",
       " 'ResponseMetadata': {'RequestId': '2d56c240-bef7-4ec2-8cb3-bdf50f2ffaad',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '2d56c240-bef7-4ec2-8cb3-bdf50f2ffaad',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '102',\n",
       "   'date': 'Wed, 06 Oct 2021 06:01:48 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sagemaker.feature_store.feature_group import FeatureGroup\n",
    "\n",
    "enable_online_store=True\n",
    "feature_store_offline_s3_uri = 's3://' + bucket\n",
    "\n",
    "record_identifier_feature_name = 'FS_ID'\n",
    "event_time_feature_name = 'FS_time'\n",
    "\n",
    "feature_group = FeatureGroup(\n",
    "    name=tripfare_feature_group_name, sagemaker_session=feature_store_session, feature_definitions=feature_definitions)\n",
    "\n",
    "feature_group.create(\n",
    "    s3_uri=feature_store_offline_s3_uri,\n",
    "    record_identifier_name=record_identifier_feature_name,\n",
    "    event_time_feature_name=event_time_feature_name,\n",
    "    role_arn=role,\n",
    "    enable_online_store=enable_online_store\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for Feature Group Creation\n",
      "Waiting for Feature Group Creation\n",
      "Waiting for Feature Group Creation\n",
      "Waiting for Feature Group Creation\n",
      "FeatureGroup fscw-tripfare-10-06-06-01 successfully created.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "def wait_for_feature_group_creation_complete(feature_group):\n",
    "    \"\"\"Helper function to wait for the completions of creating a feature group\"\"\"\n",
    "    status = feature_group.describe().get(\"FeatureGroupStatus\")\n",
    "    while status == \"Creating\":\n",
    "        print(\"Waiting for Feature Group Creation\")\n",
    "        time.sleep(5)\n",
    "        status = feature_group.describe().get(\"FeatureGroupStatus\")\n",
    "    if status != \"Created\":\n",
    "        raise SystemExit(f\"Failed to create feature group {feature_group.name}: {status}\")\n",
    "    print(f\"FeatureGroup {feature_group.name} successfully created.\")\n",
    "\n",
    "wait_for_feature_group_creation_complete(feature_group=feature_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Sklearn SageMaker Processing script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting preprocess.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile preprocess.py\n",
    "\n",
    "import glob\n",
    "import logging\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'sagemaker'])\n",
    "\n",
    "from zipfile import ZipFile\n",
    "# from time import gmtime, strftime\n",
    "import socket\n",
    "import shutil\n",
    "import json\n",
    "import time\n",
    "import argparse\n",
    "import boto3\n",
    "\n",
    "n_cores = os.cpu_count()\n",
    "# host_name = socket.gethostname()\n",
    "# print(host_name)\n",
    "# print(os.environ)\n",
    "\n",
    "# Install geopandas dependency before including pandas\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"geopandas==0.9.0\"])\n",
    "\n",
    "import pandas as pd  # noqa: E402\n",
    "import geopandas as gpd  # noqa: E402\n",
    "from sklearn.model_selection import train_test_split  # noqa: E402\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker.feature_store.feature_group import FeatureGroup\n",
    "\n",
    "def get_session(region, default_bucket):\n",
    "    \"\"\"Gets the sagemaker session based on the region.\n",
    "    Args:\n",
    "        region: the aws region to start the session\n",
    "        default_bucket: the bucket to use for storing the artifacts\n",
    "    Returns:\n",
    "        `sagemaker.session.Session instance\n",
    "    \"\"\"\n",
    "\n",
    "    boto_session = boto3.Session(region_name=region)\n",
    "\n",
    "    sagemaker_client = boto_session.client(\"sagemaker\")\n",
    "#     runtime_client = boto_session.client(\"sagemaker-runtime\")\n",
    "    return sagemaker.session.Session(\n",
    "        boto_session=boto_session,\n",
    "        sagemaker_client=sagemaker_client,\n",
    "#         sagemaker_runtime_client=runtime_client,\n",
    "        default_bucket=default_bucket,\n",
    "    )\n",
    "\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "logger.addHandler(logging.StreamHandler())\n",
    "\n",
    "def parse_args() -> None:\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--fg_name', type=str)\n",
    "    parser.add_argument('--region', type=str)\n",
    "    parser.add_argument('--bucket', type=str)\n",
    "    args, _ = parser.parse_known_args()\n",
    "    return args\n",
    "\n",
    "def extract_zones(zones_file: str, zones_dir: str):\n",
    "    logger.info(f\"Extracting zone file: {zones_file}\")\n",
    "    with ZipFile(zones_file, \"r\") as zip:\n",
    "        zip.extractall(zones_dir)\n",
    "\n",
    "\n",
    "def load_zones(zones_dir: str):\n",
    "    logging.info(f\"Loading zones from {zones_dir}\")\n",
    "    # Load the shape file and get the geometry and lat/lon\n",
    "    zone_df = gpd.read_file(os.path.join(zones_dir, \"taxi_zones.shp\"))\n",
    "    # Get centroids as EPSG code of 3310 to measure distance\n",
    "    zone_df[\"centroid\"] = zone_df.geometry.centroid.to_crs(epsg=3310)\n",
    "    # Convert cordinates to the WSG84 lat/long CRS has a EPSG code of 4326.\n",
    "    zone_df[\"latitude\"] = zone_df.centroid.to_crs(epsg=4326).x\n",
    "    zone_df[\"longitude\"] = zone_df.centroid.to_crs(epsg=4326).y\n",
    "    return zone_df\n",
    "\n",
    "\n",
    "def load_data(file_list: list):\n",
    "    # Define dates, and columns to use\n",
    "    use_cols = [\n",
    "        \"fare_amount\",\n",
    "        \"lpep_pickup_datetime\",\n",
    "        \"lpep_dropoff_datetime\",\n",
    "        \"passenger_count\",\n",
    "        \"PULocationID\",\n",
    "        \"DOLocationID\",\n",
    "    ]\n",
    "    # Concat input files with select columns\n",
    "    dfs = []\n",
    "    for file in file_list:\n",
    "        dfs.append(pd.read_csv(file, usecols=use_cols))\n",
    "    return pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "\n",
    "def enrich_data(trip_df: pd.DataFrame, zone_df: pd.DataFrame):\n",
    "    # Join trip DF to zones for poth pickup and drop off locations\n",
    "    trip_df = gpd.GeoDataFrame(\n",
    "        trip_df.join(zone_df, on=\"PULocationID\").join(\n",
    "            zone_df, on=\"DOLocationID\", rsuffix=\"_DO\", lsuffix=\"_PU\"\n",
    "        )\n",
    "    )\n",
    "    trip_df[\"geo_distance\"] = (\n",
    "        trip_df[\"centroid_PU\"].distance(trip_df[\"centroid_DO\"]) / 1000\n",
    "    )\n",
    "\n",
    "    # Add date parts\n",
    "    trip_df[\"lpep_pickup_datetime\"] = pd.to_datetime(trip_df[\"lpep_pickup_datetime\"])\n",
    "    trip_df[\"hour\"] = trip_df[\"lpep_pickup_datetime\"].dt.hour\n",
    "    trip_df[\"weekday\"] = trip_df[\"lpep_pickup_datetime\"].dt.weekday\n",
    "    trip_df[\"month\"] = trip_df[\"lpep_pickup_datetime\"].dt.month\n",
    "\n",
    "    # Get calculated duration in minutes\n",
    "    trip_df[\"lpep_dropoff_datetime\"] = pd.to_datetime(trip_df[\"lpep_dropoff_datetime\"])\n",
    "    trip_df[\"duration_minutes\"] = (\n",
    "        trip_df[\"lpep_dropoff_datetime\"] - trip_df[\"lpep_pickup_datetime\"]\n",
    "    ).dt.seconds / 60\n",
    "\n",
    "    # Rename and filter cols\n",
    "    trip_df = trip_df.rename(\n",
    "        columns={\n",
    "            \"latitude_PU\": \"pickup_latitude\",\n",
    "            \"longitude_PU\": \"pickup_longitude\",\n",
    "            \"latitude_DO\": \"dropoff_latitude\",\n",
    "            \"longitude_DO\": \"dropoff_longitude\",\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    trip_df['FS_ID'] = trip_df.index + 1000\n",
    "    current_time_sec = int(round(time.time()))\n",
    "    trip_df[\"FS_time\"] = pd.Series([current_time_sec]*len(trip_df), dtype=\"float64\")\n",
    "    return trip_df\n",
    "\n",
    "\n",
    "def clean_data(trip_df: pd.DataFrame):\n",
    "    # Remove outliers\n",
    "    trip_df = trip_df[\n",
    "        (trip_df.fare_amount > 0)\n",
    "        & (trip_df.fare_amount < 200)\n",
    "        & (trip_df.passenger_count > 0)\n",
    "        & (trip_df.duration_minutes > 0)\n",
    "        & (trip_df.duration_minutes < 120)\n",
    "        & (trip_df.geo_distance > 0)\n",
    "        & (trip_df.geo_distance < 121)\n",
    "    ].dropna()\n",
    "\n",
    "    # Filter columns\n",
    "    cols = [\n",
    "        \"fare_amount\",\n",
    "        \"passenger_count\",\n",
    "        \"pickup_latitude\",\n",
    "        \"pickup_longitude\",\n",
    "        \"dropoff_latitude\",\n",
    "        \"dropoff_longitude\",\n",
    "        \"geo_distance\",\n",
    "        \"hour\",\n",
    "        \"weekday\",\n",
    "        \"month\",\n",
    "    ]\n",
    "    \n",
    "    cols_fg = [\n",
    "        \"fare_amount\",\n",
    "        \"passenger_count\",\n",
    "        \"pickup_latitude\",\n",
    "        \"pickup_longitude\",\n",
    "        \"dropoff_latitude\",\n",
    "        \"dropoff_longitude\",\n",
    "        \"geo_distance\",\n",
    "        \"hour\",\n",
    "        \"weekday\",\n",
    "        \"month\",\n",
    "        \"FS_ID\",\n",
    "        \"FS_time\"\n",
    "    ]\n",
    "    return trip_df[cols], trip_df[cols_fg]\n",
    "\n",
    "def ingest_data(data_fg: pd.DataFrame, fg_name: str, sagemaker_session) -> None:\n",
    "    \n",
    "    # 4 threads per python process\n",
    "    num_workers = 4\n",
    "    num_processes = n_cores\n",
    "    logger.info(f'Ingesting into feature group [{fg_name}] using {num_processes} processes and {num_workers} workers')\n",
    "    fg = FeatureGroup(name=fg_name, sagemaker_session=sagemaker_session)\n",
    "    response = fg.ingest(data_frame=data_fg, max_processes=num_processes, max_workers=num_workers, wait=True)\n",
    "    \"\"\"\n",
    "    The ingest call above returns an IngestionManagerPandas instance as a response. Zero based indices of rows \n",
    "    that failed to be ingested are captured via failed_rows in this response. By asserting this count to be 0,\n",
    "    we validated that all rows were successfully ingested without a failure.\n",
    "    \"\"\"\n",
    "    assert len(response.failed_rows) == 0\n",
    "\n",
    "\n",
    "def save_files(base_dir: str, data_df: pd.DataFrame, data_fg: pd.DataFrame, fg_name: str, \n",
    "               val_size=0.2, test_size=0.05, current_host=None, sagemaker_session=None):\n",
    "        \n",
    "    logger.info(f\"Splitting {len(data_df)} rows of data into train, val, test.\")\n",
    "    if current_host == 'algo-1':\n",
    "        train_df, val_df = train_test_split(data_df, test_size=val_size, random_state=42)\n",
    "        val_df, test_df = train_test_split(val_df, test_size=test_size, random_state=42)\n",
    "\n",
    "        logger.info(f\"Writing out datasets to {base_dir}\")\n",
    "        train_df.to_csv(f\"{base_dir}/train/train-{current_host}.csv\", header=False, index=False)\n",
    "        val_df.to_csv(f\"{base_dir}/validation/validation-{current_host}.csv\", header=False, index=False)\n",
    "\n",
    "        # Save test data without header\n",
    "        test_df.to_csv(f\"{base_dir}/test/test-{current_host}.csv\", header=False, index=False)\n",
    "    else:\n",
    "        logger.info(f\"Writing out datasets to {base_dir}\")\n",
    "        data_df.to_csv(f\"{base_dir}/train/train-{current_host}.csv\", header=False, index=False)\n",
    "    \n",
    "    # batch ingestion to the feature group of all the data\n",
    "    ingest_data(data_fg, fg_name, sagemaker_session)\n",
    "\n",
    "    return \n",
    "\n",
    "def _read_json(path):  # type: (str) -> dict\n",
    "    \"\"\"Read a JSON file.\n",
    "    Args:\n",
    "        path (str): Path to the file.\n",
    "    Returns:\n",
    "        (dict[object, object]): A dictionary representation of the JSON file.\n",
    "    \"\"\"\n",
    "    with open(path, \"r\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def main(base_dir: str, args: argparse.Namespace):\n",
    "    # Input data files\n",
    "    input_dir = os.path.join(base_dir, \"input/data\")\n",
    "    input_file_list = glob.glob(f\"{input_dir}/*.csv\")\n",
    "    logger.info(f\"Input file list: {input_file_list}\")\n",
    "    \n",
    "    config_file_list = glob.glob(\"/opt/ml/config/*.json\")\n",
    "    logger.info(f\"config file list: {config_file_list}\")\n",
    "\n",
    "    hosts = _read_json(\"/opt/ml/config/resourceconfig.json\")\n",
    "    logger.info(hosts)\n",
    "    current_host = hosts[\"current_host\"]\n",
    "    logger.info(current_host)\n",
    "        \n",
    "    if len(input_file_list) == 0:\n",
    "        raise Exception(f\"No input files found in {input_dir}\")\n",
    "\n",
    "    # Input zones file\n",
    "    zones_dir = os.path.join(base_dir, \"input/zones\")\n",
    "    zones_file = os.path.join(zones_dir, \"taxi_zones.zip\")\n",
    "    if not os.path.exists(zones_file):\n",
    "        raise Exception(f\"Zones file {zones_file} does not exist\")\n",
    "\n",
    "    # Extract and load taxi zones geopandas dataframe\n",
    "    extract_zones(zones_file, zones_dir)\n",
    "    zone_df = load_zones(zones_dir)\n",
    "\n",
    "    # Load input files\n",
    "    data_df = load_data(input_file_list)\n",
    "    data_df = enrich_data(data_df, zone_df)\n",
    "    data_df, data_fg = clean_data(data_df)\n",
    "\n",
    "    fg_name = args.fg_name\n",
    "    \n",
    "    sagemaker_session = get_session(args.region, args.bucket)\n",
    "    \n",
    "    return save_files(base_dir, data_df, data_fg, fg_name, current_host=current_host, sagemaker_session=sagemaker_session)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    logger.info(\"Starting preprocessing.\")\n",
    "    args = parse_args()\n",
    "    base_dir = \"/opt/ml/processing\"\n",
    "    main(base_dir, args)\n",
    "    logger.info(\"Done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'process_script' (str)\n"
     ]
    }
   ],
   "source": [
    "process_script = os.getcwd() + '/preprocess.py'\n",
    "%store process_script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 07\n",
    "train_path = f\"s3://{bucket}/{prefix}/train\"\n",
    "validation_path = f\"s3://{bucket}/{prefix}/validation\"\n",
    "test_path = f\"s3://{bucket}/{prefix}/test\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Name:  sm-immday-skprocessing-2021-10-06-06-53-03-126\n",
      "Inputs:  [{'InputName': 'input-1', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-631450739534/sagemaker/DEMO-xgboost-tripfare/input/data/', 'LocalPath': '/opt/ml/processing/input/data', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'ShardedByS3Key', 'S3CompressionType': 'None'}}, {'InputName': 'input-2', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-631450739534/sagemaker/DEMO-xgboost-tripfare/input/zones/', 'LocalPath': '/opt/ml/processing/input/zones', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'code', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-631450739534/sm-immday-skprocessing-2021-10-06-06-53-03-126/input/code/preprocess.py', 'LocalPath': '/opt/ml/processing/input/code', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}]\n",
      "Outputs:  [{'OutputName': 'train', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-631450739534/sagemaker/DEMO-xgboost-tripfare/train', 'LocalPath': '/opt/ml/processing/train', 'S3UploadMode': 'EndOfJob'}}, {'OutputName': 'validation', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-631450739534/sagemaker/DEMO-xgboost-tripfare/validation', 'LocalPath': '/opt/ml/processing/validation', 'S3UploadMode': 'EndOfJob'}}, {'OutputName': 'test', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-631450739534/sagemaker/DEMO-xgboost-tripfare/test', 'LocalPath': '/opt/ml/processing/test', 'S3UploadMode': 'EndOfJob'}}]\n",
      "..........................\u001b[35mCollecting sagemaker\n",
      "  Downloading sagemaker-2.59.7.tar.gz (444 kB)\u001b[0m\n",
      "\u001b[35mCollecting attrs\n",
      "  Downloading attrs-21.2.0-py2.py3-none-any.whl (53 kB)\u001b[0m\n",
      "\u001b[35mCollecting boto3>=1.16.32\n",
      "  Downloading boto3-1.18.55-py3-none-any.whl (131 kB)\u001b[0m\n",
      "\u001b[35mCollecting google-pasta\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: numpy>=1.9.0 in /miniconda3/lib/python3.7/site-packages (from sagemaker) (1.19.2)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: protobuf>=3.1 in /miniconda3/lib/python3.7/site-packages (from sagemaker) (3.17.3)\u001b[0m\n",
      "\u001b[35mCollecting protobuf3-to-dict>=0.1.5\n",
      "  Downloading protobuf3-to-dict-0.1.5.tar.gz (3.5 kB)\u001b[0m\n",
      "\u001b[35mCollecting smdebug_rulesconfig==1.0.1\n",
      "  Downloading smdebug_rulesconfig-1.0.1-py2.py3-none-any.whl (20 kB)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: importlib-metadata>=1.4.0 in /miniconda3/lib/python3.7/site-packages (from sagemaker) (4.7.1)\u001b[0m\n",
      "\u001b[35mCollecting packaging>=20.0\n",
      "  Downloading packaging-21.0-py3-none-any.whl (40 kB)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: pandas in /miniconda3/lib/python3.7/site-packages (from sagemaker) (1.1.3)\u001b[0m\n",
      "\u001b[35mCollecting pathos\n",
      "  Downloading pathos-0.2.8-py2.py3-none-any.whl (81 kB)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: jmespath<1.0.0,>=0.7.1 in /miniconda3/lib/python3.7/site-packages (from boto3>=1.16.32->sagemaker) (0.10.0)\u001b[0m\n",
      "\u001b[35mCollecting botocore<1.22.0,>=1.21.55\n",
      "  Downloading botocore-1.21.55-py3-none-any.whl (8.0 MB)\u001b[0m\n",
      "\u001b[35mCollecting s3transfer<0.6.0,>=0.5.0\n",
      "  Downloading s3transfer-0.5.0-py3-none-any.whl (79 kB)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /miniconda3/lib/python3.7/site-packages (from botocore<1.22.0,>=1.21.55->boto3>=1.16.32->sagemaker) (2.8.1)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: urllib3<1.27,>=1.25.4 in /miniconda3/lib/python3.7/site-packages (from botocore<1.22.0,>=1.21.55->boto3>=1.16.32->sagemaker) (1.25.11)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: zipp>=0.5 in /miniconda3/lib/python3.7/site-packages (from importlib-metadata>=1.4.0->sagemaker) (3.5.0)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: typing-extensions>=3.6.4 in /miniconda3/lib/python3.7/site-packages (from importlib-metadata>=1.4.0->sagemaker) (3.10.0.0)\u001b[0m\n",
      "\u001b[35mCollecting pyparsing>=2.0.2\n",
      "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: six>=1.9 in /miniconda3/lib/python3.7/site-packages (from protobuf>=3.1->sagemaker) (1.15.0)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: pytz>=2017.2 in /miniconda3/lib/python3.7/site-packages (from pandas->sagemaker) (2021.1)\u001b[0m\n",
      "\u001b[35mCollecting multiprocess>=0.70.12\n",
      "  Downloading multiprocess-0.70.12.2-py37-none-any.whl (112 kB)\u001b[0m\n",
      "\u001b[35mCollecting dill>=0.3.4\n",
      "  Downloading dill-0.3.4-py2.py3-none-any.whl (86 kB)\u001b[0m\n",
      "\u001b[35mCollecting ppft>=1.6.6.4\n",
      "  Downloading ppft-1.6.6.4-py3-none-any.whl (65 kB)\u001b[0m\n",
      "\u001b[35mCollecting pox>=0.3.0\n",
      "  Downloading pox-0.3.0-py2.py3-none-any.whl (30 kB)\u001b[0m\n",
      "\u001b[35mBuilding wheels for collected packages: sagemaker, protobuf3-to-dict\n",
      "  Building wheel for sagemaker (setup.py): started\n",
      "  Building wheel for sagemaker (setup.py): finished with status 'done'\n",
      "  Created wheel for sagemaker: filename=sagemaker-2.59.7-py2.py3-none-any.whl size=619156 sha256=0de0a2250a79c84577caf8610742c7b39fb684386a1060adc92d122edc0a9ff3\n",
      "  Stored in directory: /root/.cache/pip/wheels/11/1f/2e/9141fc8902631ae6438b2fdede2edefafa5b0f809e1aabb86d\n",
      "  Building wheel for protobuf3-to-dict (setup.py): started\u001b[0m\n",
      "\u001b[35m  Building wheel for protobuf3-to-dict (setup.py): finished with status 'done'\n",
      "  Created wheel for protobuf3-to-dict: filename=protobuf3_to_dict-0.1.5-py3-none-any.whl size=4030 sha256=c272f2c71cbfc2fd5a1d968a9a7c918ddd187c989c29f092a1b4aef50fc42ff0\n",
      "  Stored in directory: /root/.cache/pip/wheels/ce/a0/8b/995ce2fbaf0e9fe7eb91da84e99e84d1b35cfaa555f2b8f1c7\u001b[0m\n",
      "\u001b[35mSuccessfully built sagemaker protobuf3-to-dict\u001b[0m\n",
      "\u001b[35mInstalling collected packages: dill, botocore, s3transfer, pyparsing, ppft, pox, multiprocess, smdebug-rulesconfig, protobuf3-to-dict, pathos, packaging, google-pasta, boto3, attrs, sagemaker\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.19.4\n",
      "    Uninstalling botocore-1.19.4:\n",
      "      Successfully uninstalled botocore-1.19.4\u001b[0m\n",
      "\u001b[35m  Attempting uninstall: s3transfer\n",
      "    Found existing installation: s3transfer 0.3.7\n",
      "    Uninstalling s3transfer-0.3.7:\n",
      "      Successfully uninstalled s3transfer-0.3.7\n",
      "  Attempting uninstall: boto3\n",
      "    Found existing installation: boto3 1.16.4\n",
      "    Uninstalling boto3-1.16.4:\n",
      "      Successfully uninstalled boto3-1.16.4\u001b[0m\n",
      "\u001b[35mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\u001b[0m\n",
      "\u001b[35msagemaker-sklearn-container 2.0 requires boto3==1.16.4, but you have boto3 1.18.55 which is incompatible.\u001b[0m\n",
      "\u001b[35msagemaker-sklearn-container 2.0 requires botocore==1.19.4, but you have botocore 1.21.55 which is incompatible.\u001b[0m\n",
      "\u001b[35mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[35mSuccessfully installed attrs-21.2.0 boto3-1.18.55 botocore-1.21.55 dill-0.3.4 google-pasta-0.2.0 multiprocess-0.70.12.2 packaging-21.0 pathos-0.2.8 pox-0.3.0 ppft-1.6.6.4 protobuf3-to-dict-0.1.5 pyparsing-2.4.7 s3transfer-0.5.0 sagemaker-2.59.7 smdebug-rulesconfig-1.0.1\u001b[0m\n",
      "\u001b[35mCollecting geopandas==0.9.0\n",
      "  Downloading geopandas-0.9.0-py2.py3-none-any.whl (994 kB)\u001b[0m\n",
      "\u001b[35mCollecting pyproj>=2.2.0\n",
      "  Downloading pyproj-3.2.1-cp37-cp37m-manylinux2010_x86_64.whl (6.3 MB)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: pandas>=0.24.0 in /miniconda3/lib/python3.7/site-packages (from geopandas==0.9.0) (1.1.3)\u001b[0m\n",
      "\u001b[35mCollecting fiona>=1.8\n",
      "  Downloading Fiona-1.8.20-cp37-cp37m-manylinux1_x86_64.whl (15.4 MB)\u001b[0m\n",
      "\u001b[35mCollecting shapely>=1.6\n",
      "  Downloading Shapely-1.7.1-cp37-cp37m-manylinux1_x86_64.whl (1.0 MB)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: attrs>=17 in /miniconda3/lib/python3.7/site-packages (from fiona>=1.8->geopandas==0.9.0) (21.2.0)\u001b[0m\n",
      "\u001b[35mCollecting cligj>=0.5\n",
      "  Downloading cligj-0.7.2-py3-none-any.whl (7.1 kB)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: setuptools in /miniconda3/lib/python3.7/site-packages (from fiona>=1.8->geopandas==0.9.0) (52.0.0.post20210125)\u001b[0m\n",
      "\u001b[35mCollecting munch\n",
      "  Downloading munch-2.5.0-py2.py3-none-any.whl (10 kB)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: certifi in /miniconda3/lib/python3.7/site-packages (from fiona>=1.8->geopandas==0.9.0) (2021.5.30)\u001b[0m\n",
      "\u001b[35mCollecting click-plugins>=1.0\n",
      "  Downloading click_plugins-1.1.1-py2.py3-none-any.whl (7.5 kB)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: click>=4.0 in /miniconda3/lib/python3.7/site-packages (from fiona>=1.8->geopandas==0.9.0) (8.0.1)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: six>=1.7 in /miniconda3/lib/python3.7/site-packages (from fiona>=1.8->geopandas==0.9.0) (1.15.0)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: importlib-metadata in /miniconda3/lib/python3.7/site-packages (from click>=4.0->fiona>=1.8->geopandas==0.9.0) (4.7.1)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: python-dateutil>=2.7.3 in /miniconda3/lib/python3.7/site-packages (from pandas>=0.24.0->geopandas==0.9.0) (2.8.1)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: pytz>=2017.2 in /miniconda3/lib/python3.7/site-packages (from pandas>=0.24.0->geopandas==0.9.0) (2021.1)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: numpy>=1.15.4 in /miniconda3/lib/python3.7/site-packages (from pandas>=0.24.0->geopandas==0.9.0) (1.19.2)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: typing-extensions>=3.6.4 in /miniconda3/lib/python3.7/site-packages (from importlib-metadata->click>=4.0->fiona>=1.8->geopandas==0.9.0) (3.10.0.0)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: zipp>=0.5 in /miniconda3/lib/python3.7/site-packages (from importlib-metadata->click>=4.0->fiona>=1.8->geopandas==0.9.0) (3.5.0)\u001b[0m\n",
      "\u001b[34mCollecting sagemaker\n",
      "  Downloading sagemaker-2.59.7.tar.gz (444 kB)\u001b[0m\n",
      "\u001b[34mCollecting attrs\n",
      "  Downloading attrs-21.2.0-py2.py3-none-any.whl (53 kB)\u001b[0m\n",
      "\u001b[34mCollecting boto3>=1.16.32\n",
      "  Downloading boto3-1.18.55-py3-none-any.whl (131 kB)\u001b[0m\n",
      "\u001b[34mCollecting google-pasta\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.9.0 in /miniconda3/lib/python3.7/site-packages (from sagemaker) (1.19.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: protobuf>=3.1 in /miniconda3/lib/python3.7/site-packages (from sagemaker) (3.17.3)\u001b[0m\n",
      "\u001b[34mCollecting protobuf3-to-dict>=0.1.5\n",
      "  Downloading protobuf3-to-dict-0.1.5.tar.gz (3.5 kB)\u001b[0m\n",
      "\u001b[34mCollecting smdebug_rulesconfig==1.0.1\n",
      "  Downloading smdebug_rulesconfig-1.0.1-py2.py3-none-any.whl (20 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: importlib-metadata>=1.4.0 in /miniconda3/lib/python3.7/site-packages (from sagemaker) (4.7.1)\u001b[0m\n",
      "\u001b[34mCollecting packaging>=20.0\n",
      "  Downloading packaging-21.0-py3-none-any.whl (40 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas in /miniconda3/lib/python3.7/site-packages (from sagemaker) (1.1.3)\u001b[0m\n",
      "\u001b[34mCollecting pathos\n",
      "  Downloading pathos-0.2.8-py2.py3-none-any.whl (81 kB)\u001b[0m\n",
      "\u001b[34mCollecting s3transfer<0.6.0,>=0.5.0\n",
      "  Downloading s3transfer-0.5.0-py3-none-any.whl (79 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jmespath<1.0.0,>=0.7.1 in /miniconda3/lib/python3.7/site-packages (from boto3>=1.16.32->sagemaker) (0.10.0)\u001b[0m\n",
      "\u001b[34mCollecting botocore<1.22.0,>=1.21.55\n",
      "  Downloading botocore-1.21.55-py3-none-any.whl (8.0 MB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /miniconda3/lib/python3.7/site-packages (from botocore<1.22.0,>=1.21.55->boto3>=1.16.32->sagemaker) (2.8.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<1.27,>=1.25.4 in /miniconda3/lib/python3.7/site-packages (from botocore<1.22.0,>=1.21.55->boto3>=1.16.32->sagemaker) (1.25.11)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: zipp>=0.5 in /miniconda3/lib/python3.7/site-packages (from importlib-metadata>=1.4.0->sagemaker) (3.5.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions>=3.6.4 in /miniconda3/lib/python3.7/site-packages (from importlib-metadata>=1.4.0->sagemaker) (3.10.0.0)\u001b[0m\n",
      "\u001b[34mCollecting pyparsing>=2.0.2\n",
      "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six>=1.9 in /miniconda3/lib/python3.7/site-packages (from protobuf>=3.1->sagemaker) (1.15.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2017.2 in /miniconda3/lib/python3.7/site-packages (from pandas->sagemaker) (2021.1)\u001b[0m\n",
      "\u001b[34mCollecting pox>=0.3.0\n",
      "  Downloading pox-0.3.0-py2.py3-none-any.whl (30 kB)\u001b[0m\n",
      "\u001b[34mCollecting dill>=0.3.4\n",
      "  Downloading dill-0.3.4-py2.py3-none-any.whl (86 kB)\u001b[0m\n",
      "\u001b[34mCollecting multiprocess>=0.70.12\n",
      "  Downloading multiprocess-0.70.12.2-py37-none-any.whl (112 kB)\u001b[0m\n",
      "\u001b[34mCollecting ppft>=1.6.6.4\n",
      "  Downloading ppft-1.6.6.4-py3-none-any.whl (65 kB)\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: sagemaker, protobuf3-to-dict\n",
      "  Building wheel for sagemaker (setup.py): started\n",
      "  Building wheel for sagemaker (setup.py): finished with status 'done'\n",
      "  Created wheel for sagemaker: filename=sagemaker-2.59.7-py2.py3-none-any.whl size=619156 sha256=0de0a2250a79c84577caf8610742c7b39fb684386a1060adc92d122edc0a9ff3\n",
      "  Stored in directory: /root/.cache/pip/wheels/11/1f/2e/9141fc8902631ae6438b2fdede2edefafa5b0f809e1aabb86d\n",
      "  Building wheel for protobuf3-to-dict (setup.py): started\n",
      "  Building wheel for protobuf3-to-dict (setup.py): finished with status 'done'\n",
      "  Created wheel for protobuf3-to-dict: filename=protobuf3_to_dict-0.1.5-py3-none-any.whl size=4030 sha256=c272f2c71cbfc2fd5a1d968a9a7c918ddd187c989c29f092a1b4aef50fc42ff0\n",
      "  Stored in directory: /root/.cache/pip/wheels/ce/a0/8b/995ce2fbaf0e9fe7eb91da84e99e84d1b35cfaa555f2b8f1c7\u001b[0m\n",
      "\u001b[34mSuccessfully built sagemaker protobuf3-to-dict\u001b[0m\n",
      "\u001b[34mInstalling collected packages: dill, botocore, s3transfer, pyparsing, ppft, pox, multiprocess, smdebug-rulesconfig, protobuf3-to-dict, pathos, packaging, google-pasta, boto3, attrs, sagemaker\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.19.4\n",
      "    Uninstalling botocore-1.19.4:\n",
      "      Successfully uninstalled botocore-1.19.4\n",
      "  Attempting uninstall: s3transfer\n",
      "    Found existing installation: s3transfer 0.3.7\n",
      "    Uninstalling s3transfer-0.3.7:\n",
      "      Successfully uninstalled s3transfer-0.3.7\u001b[0m\n",
      "\u001b[34m  Attempting uninstall: boto3\n",
      "    Found existing installation: boto3 1.16.4\n",
      "    Uninstalling boto3-1.16.4:\n",
      "      Successfully uninstalled boto3-1.16.4\u001b[0m\n",
      "\u001b[34mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\u001b[0m\n",
      "\u001b[34msagemaker-sklearn-container 2.0 requires boto3==1.16.4, but you have boto3 1.18.55 which is incompatible.\u001b[0m\n",
      "\u001b[34msagemaker-sklearn-container 2.0 requires botocore==1.19.4, but you have botocore 1.21.55 which is incompatible.\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34mSuccessfully installed attrs-21.2.0 boto3-1.18.55 botocore-1.21.55 dill-0.3.4 google-pasta-0.2.0 multiprocess-0.70.12.2 packaging-21.0 pathos-0.2.8 pox-0.3.0 ppft-1.6.6.4 protobuf3-to-dict-0.1.5 pyparsing-2.4.7 s3transfer-0.5.0 sagemaker-2.59.7 smdebug-rulesconfig-1.0.1\u001b[0m\n",
      "\u001b[34mCollecting geopandas==0.9.0\n",
      "  Downloading geopandas-0.9.0-py2.py3-none-any.whl (994 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas>=0.24.0 in /miniconda3/lib/python3.7/site-packages (from geopandas==0.9.0) (1.1.3)\u001b[0m\n",
      "\u001b[34mCollecting shapely>=1.6\n",
      "  Downloading Shapely-1.7.1-cp37-cp37m-manylinux1_x86_64.whl (1.0 MB)\u001b[0m\n",
      "\u001b[34mCollecting pyproj>=2.2.0\n",
      "  Downloading pyproj-3.2.1-cp37-cp37m-manylinux2010_x86_64.whl (6.3 MB)\u001b[0m\n",
      "\u001b[34mCollecting fiona>=1.8\n",
      "  Downloading Fiona-1.8.20-cp37-cp37m-manylinux1_x86_64.whl (15.4 MB)\u001b[0m\n",
      "\u001b[34mCollecting cligj>=0.5\n",
      "  Downloading cligj-0.7.2-py3-none-any.whl (7.1 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: attrs>=17 in /miniconda3/lib/python3.7/site-packages (from fiona>=1.8->geopandas==0.9.0) (21.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: setuptools in /miniconda3/lib/python3.7/site-packages (from fiona>=1.8->geopandas==0.9.0) (52.0.0.post20210125)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: click>=4.0 in /miniconda3/lib/python3.7/site-packages (from fiona>=1.8->geopandas==0.9.0) (8.0.1)\u001b[0m\n",
      "\u001b[34mCollecting munch\n",
      "  Downloading munch-2.5.0-py2.py3-none-any.whl (10 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six>=1.7 in /miniconda3/lib/python3.7/site-packages (from fiona>=1.8->geopandas==0.9.0) (1.15.0)\u001b[0m\n",
      "\u001b[34mCollecting click-plugins>=1.0\n",
      "  Downloading click_plugins-1.1.1-py2.py3-none-any.whl (7.5 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi in /miniconda3/lib/python3.7/site-packages (from fiona>=1.8->geopandas==0.9.0) (2021.5.30)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: importlib-metadata in /miniconda3/lib/python3.7/site-packages (from click>=4.0->fiona>=1.8->geopandas==0.9.0) (4.7.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.15.4 in /miniconda3/lib/python3.7/site-packages (from pandas>=0.24.0->geopandas==0.9.0) (1.19.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.7.3 in /miniconda3/lib/python3.7/site-packages (from pandas>=0.24.0->geopandas==0.9.0) (2.8.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2017.2 in /miniconda3/lib/python3.7/site-packages (from pandas>=0.24.0->geopandas==0.9.0) (2021.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions>=3.6.4 in /miniconda3/lib/python3.7/site-packages (from importlib-metadata->click>=4.0->fiona>=1.8->geopandas==0.9.0) (3.10.0.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: zipp>=0.5 in /miniconda3/lib/python3.7/site-packages (from importlib-metadata->click>=4.0->fiona>=1.8->geopandas==0.9.0) (3.5.0)\u001b[0m\n",
      "\u001b[34mInstalling collected packages: munch, cligj, click-plugins, shapely, pyproj, fiona, geopandas\u001b[0m\n",
      "\u001b[35mInstalling collected packages: munch, cligj, click-plugins, shapely, pyproj, fiona, geopandas\u001b[0m\n",
      "\u001b[35mSuccessfully installed click-plugins-1.1.1 cligj-0.7.2 fiona-1.8.20 geopandas-0.9.0 munch-2.5.0 pyproj-3.2.1 shapely-1.7.1\u001b[0m\n",
      "\u001b[35mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34mSuccessfully installed click-plugins-1.1.1 cligj-0.7.2 fiona-1.8.20 geopandas-0.9.0 munch-2.5.0 pyproj-3.2.1 shapely-1.7.1\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[35mStarting preprocessing.\u001b[0m\n",
      "\u001b[35mInput file list: ['/opt/ml/processing/input/data/green_tripdata_2018-11.csv']\u001b[0m\n",
      "\u001b[35mconfig file list: ['/opt/ml/config/processingjobconfig.json', '/opt/ml/config/resourceconfig.json']\u001b[0m\n",
      "\u001b[35m{'current_host': 'algo-2', 'hosts': ['algo-1', 'algo-2']}\u001b[0m\n",
      "\u001b[35malgo-2\u001b[0m\n",
      "\u001b[35mExtracting zone file: /opt/ml/processing/input/zones/taxi_zones.zip\u001b[0m\n",
      "\u001b[35mLoading zones from /opt/ml/processing/input/zones\u001b[0m\n",
      "\u001b[34mStarting preprocessing.\u001b[0m\n",
      "\u001b[34mInput file list: ['/opt/ml/processing/input/data/green_tripdata_2018-12.csv', '/opt/ml/processing/input/data/green_tripdata_2018-10.csv']\u001b[0m\n",
      "\u001b[34mconfig file list: ['/opt/ml/config/resourceconfig.json', '/opt/ml/config/processingjobconfig.json']\u001b[0m\n",
      "\u001b[34m{'current_host': 'algo-1', 'hosts': ['algo-1', 'algo-2']}\u001b[0m\n",
      "\u001b[34malgo-1\u001b[0m\n",
      "\u001b[34mExtracting zone file: /opt/ml/processing/input/zones/taxi_zones.zip\u001b[0m\n",
      "\u001b[34mLoading zones from /opt/ml/processing/input/zones\u001b[0m\n",
      "\u001b[35mSplitting 551424 rows of data into train, val, test.\u001b[0m\n",
      "\u001b[35mWriting out datasets to /opt/ml/processing\u001b[0m\n",
      "\u001b[35mIngesting into feature group [fscw-tripfare-10-06-06-01] using 16 processes and 4 workers\u001b[0m\n",
      "\u001b[35mStarted ingesting index 8616 to 17232\u001b[0m\n",
      "\u001b[35mStarted ingesting index 0 to 8616\u001b[0m\n",
      "\u001b[35mStarted ingesting index 17232 to 25848\u001b[0m\n",
      "\u001b[35mStarted ingesting index 25848 to 34464\u001b[0m\n",
      "\u001b[35mStarted ingesting index 17232 to 25848\u001b[0m\n",
      "\u001b[35mStarted ingesting index 25848 to 34464\u001b[0m\n",
      "\u001b[35mStarted ingesting index 0 to 8616\u001b[0m\n",
      "\u001b[35mStarted ingesting index 17232 to 25848\u001b[0m\n",
      "\u001b[35mStarted ingesting index 0 to 8616\u001b[0m\n",
      "\u001b[35mStarted ingesting index 0 to 8616\u001b[0m\n",
      "\u001b[35mStarted ingesting index 17232 to 25848\u001b[0m\n",
      "\u001b[35mStarted ingesting index 8616 to 17232\u001b[0m\n",
      "\u001b[35mStarted ingesting index 25848 to 34464\u001b[0m\n",
      "\u001b[35mStarted ingesting index 8616 to 17232\u001b[0m\n",
      "\u001b[35mStarted ingesting index 8616 to 17232\u001b[0m\n",
      "\u001b[35mStarted ingesting index 25848 to 34464\u001b[0m\n",
      "\u001b[35mStarted ingesting index 8616 to 17232\u001b[0m\n",
      "\u001b[35mStarted ingesting index 17232 to 25848\u001b[0m\n",
      "\u001b[35mStarted ingesting index 17232 to 25848\u001b[0m\n",
      "\u001b[35mStarted ingesting index 25848 to 34464\u001b[0m\n",
      "\u001b[35mStarted ingesting index 0 to 8616\u001b[0m\n",
      "\u001b[35mStarted ingesting index 25848 to 34464\u001b[0m\n",
      "\u001b[35mStarted ingesting index 8616 to 17232\u001b[0m\n",
      "\u001b[35mStarted ingesting index 8616 to 17232\u001b[0m\n",
      "\u001b[35mStarted ingesting index 0 to 8616\u001b[0m\n",
      "\u001b[35mStarted ingesting index 8616 to 17232\u001b[0m\n",
      "\u001b[35mStarted ingesting index 25848 to 34464\u001b[0m\n",
      "\u001b[35mStarted ingesting index 8616 to 17232\u001b[0m\n",
      "\u001b[35mStarted ingesting index 17232 to 25848\u001b[0m\n",
      "\u001b[35mStarted ingesting index 0 to 8616\u001b[0m\n",
      "\u001b[35mStarted ingesting index 0 to 8616\u001b[0m\n",
      "\u001b[35mStarted ingesting index 17232 to 25848\u001b[0m\n",
      "\u001b[35mStarted ingesting index 0 to 8616\u001b[0m\n",
      "\u001b[35mStarted ingesting index 17232 to 25848\u001b[0m\n",
      "\u001b[35mStarted ingesting index 8616 to 17232\u001b[0m\n",
      "\u001b[35mStarted ingesting index 25848 to 34464\u001b[0m\n",
      "\u001b[35mStarted ingesting index 17232 to 25848\u001b[0m\n",
      "\u001b[35mStarted ingesting index 25848 to 34464\u001b[0m\n",
      "\u001b[35mStarted ingesting index 25848 to 34464\u001b[0m\n",
      "\u001b[35mStarted ingesting index 25848 to 34464\u001b[0m\n",
      "\u001b[35mStarted ingesting index 0 to 8616\u001b[0m\n",
      "\u001b[35mStarted ingesting index 0 to 8616\u001b[0m\n",
      "\u001b[35mStarted ingesting index 0 to 8616\u001b[0m\n",
      "\u001b[35mStarted ingesting index 17232 to 25848\u001b[0m\n",
      "\u001b[35mStarted ingesting index 8616 to 17232\u001b[0m\n",
      "\u001b[35mStarted ingesting index 8616 to 17232\u001b[0m\n",
      "\u001b[35mStarted ingesting index 25848 to 34464\u001b[0m\n",
      "\u001b[35mStarted ingesting index 17232 to 25848\u001b[0m\n",
      "\u001b[35mStarted ingesting index 17232 to 25848\u001b[0m\n",
      "\u001b[35mStarted ingesting index 0 to 8616\u001b[0m\n",
      "\u001b[35mStarted ingesting index 8616 to 17232\u001b[0m\n",
      "\u001b[35mStarted ingesting index 8616 to 17232\u001b[0m\n",
      "\u001b[35mStarted ingesting index 8616 to 17232\u001b[0m\n",
      "\u001b[35mStarted ingesting index 25848 to 34464\u001b[0m\n",
      "\u001b[35mStarted ingesting index 25848 to 34464\u001b[0m\n",
      "\u001b[35mStarted ingesting index 0 to 8616\u001b[0m\n",
      "\u001b[35mStarted ingesting index 17232 to 25848\u001b[0m\n",
      "\u001b[35mStarted ingesting index 25848 to 34464\u001b[0m\n",
      "\u001b[35mStarted ingesting index 0 to 8616\u001b[0m\n",
      "\u001b[35mStarted ingesting index 0 to 8616\u001b[0m\n",
      "\u001b[35mStarted ingesting index 17232 to 25848\u001b[0m\n",
      "\u001b[35mStarted ingesting index 17232 to 25848\u001b[0m\n",
      "\u001b[35mStarted ingesting index 8616 to 17232\u001b[0m\n",
      "\u001b[35mStarted ingesting index 25848 to 34464\u001b[0m\n",
      "\u001b[34mSplitting 1176620 rows of data into train, val, test.\u001b[0m\n",
      "\u001b[34mWriting out datasets to /opt/ml/processing\u001b[0m\n",
      "\u001b[34mIngesting into feature group [fscw-tripfare-10-06-06-01] using 16 processes and 4 workers\u001b[0m\n",
      "\u001b[34mStarted ingesting index 0 to 18385\u001b[0m\n",
      "\u001b[34mStarted ingesting index 36770 to 55155\u001b[0m\n",
      "\u001b[34mStarted ingesting index 55155 to 73539\u001b[0m\n",
      "\u001b[34mStarted ingesting index 36770 to 55155\u001b[0m\n",
      "\u001b[34mStarted ingesting index 18385 to 36770\u001b[0m\n",
      "\u001b[34mStarted ingesting index 36770 to 55155\u001b[0m\n",
      "\u001b[34mStarted ingesting index 55155 to 73539\u001b[0m\n",
      "\u001b[34mStarted ingesting index 0 to 18385\u001b[0m\n",
      "\u001b[34mStarted ingesting index 55155 to 73539\u001b[0m\n",
      "\u001b[34mStarted ingesting index 36770 to 55155\u001b[0m\n",
      "\u001b[34mStarted ingesting index 18385 to 36770\u001b[0m\n",
      "\u001b[34mStarted ingesting index 36770 to 55155\u001b[0m\n",
      "\u001b[34mStarted ingesting index 0 to 18385\u001b[0m\n",
      "\u001b[34mStarted ingesting index 55155 to 73539\u001b[0m\n",
      "\u001b[34mStarted ingesting index 0 to 18385\u001b[0m\n",
      "\u001b[34mStarted ingesting index 18385 to 36770\u001b[0m\n",
      "\u001b[34mStarted ingesting index 18385 to 36770\u001b[0m\n",
      "\u001b[34mStarted ingesting index 18385 to 36770\u001b[0m\n",
      "\u001b[34mStarted ingesting index 0 to 18385\u001b[0m\n",
      "\u001b[34mStarted ingesting index 55155 to 73539\u001b[0m\n",
      "\u001b[34mStarted ingesting index 0 to 18385\u001b[0m\n",
      "\u001b[34mStarted ingesting index 55155 to 73539\u001b[0m\n",
      "\u001b[34mStarted ingesting index 18385 to 36770\u001b[0m\n",
      "\u001b[34mStarted ingesting index 18385 to 36770\u001b[0m\n",
      "\u001b[34mStarted ingesting index 36770 to 55155\u001b[0m\n",
      "\u001b[34mStarted ingesting index 36770 to 55155\u001b[0m\n",
      "\u001b[34mStarted ingesting index 55155 to 73539\u001b[0m\n",
      "\u001b[34mStarted ingesting index 0 to 18385\u001b[0m\n",
      "\u001b[34mStarted ingesting index 55155 to 73539\u001b[0m\n",
      "\u001b[34mStarted ingesting index 0 to 18385\u001b[0m\n",
      "\u001b[34mStarted ingesting index 36770 to 55155\u001b[0m\n",
      "\u001b[34mStarted ingesting index 18385 to 36770\u001b[0m\n",
      "\u001b[34mStarted ingesting index 18385 to 36770\u001b[0m\n",
      "\u001b[34mStarted ingesting index 36770 to 55155\u001b[0m\n",
      "\u001b[34mStarted ingesting index 0 to 18385\u001b[0m\n",
      "\u001b[34mStarted ingesting index 55155 to 73539\u001b[0m\n",
      "\u001b[34mStarted ingesting index 55155 to 73539\u001b[0m\n",
      "\u001b[34mStarted ingesting index 36770 to 55155\u001b[0m\n",
      "\u001b[34mStarted ingesting index 0 to 18385\u001b[0m\n",
      "\u001b[34mStarted ingesting index 18385 to 36770\u001b[0m\n",
      "\u001b[34mStarted ingesting index 36770 to 55155\u001b[0m\n",
      "\u001b[34mStarted ingesting index 0 to 18385\u001b[0m\n",
      "\u001b[34mStarted ingesting index 0 to 18385\u001b[0m\n",
      "\u001b[34mStarted ingesting index 36770 to 55155\u001b[0m\n",
      "\u001b[34mStarted ingesting index 55155 to 73539\u001b[0m\n",
      "\u001b[34mStarted ingesting index 18385 to 36770\u001b[0m\n",
      "\u001b[34mStarted ingesting index 18385 to 36770\u001b[0m\n",
      "\u001b[34mStarted ingesting index 36770 to 55155\u001b[0m\n",
      "\u001b[34mStarted ingesting index 55155 to 73539\u001b[0m\n",
      "\u001b[34mStarted ingesting index 55155 to 73539\u001b[0m\n",
      "\u001b[34mStarted ingesting index 18385 to 36770\u001b[0m\n",
      "\u001b[34mStarted ingesting index 0 to 18385\u001b[0m\n",
      "\u001b[34mStarted ingesting index 55155 to 73539\u001b[0m\n",
      "\u001b[34mStarted ingesting index 36770 to 55155\u001b[0m\n",
      "\u001b[34mStarted ingesting index 0 to 18385\u001b[0m\n",
      "\u001b[34mStarted ingesting index 18385 to 36770\u001b[0m\n",
      "\u001b[34mStarted ingesting index 18385 to 36770\u001b[0m\n",
      "\u001b[34mStarted ingesting index 0 to 18385\u001b[0m\n",
      "\u001b[34mStarted ingesting index 55155 to 73539\u001b[0m\n",
      "\u001b[34mStarted ingesting index 36770 to 55155\u001b[0m\n",
      "\u001b[34mStarted ingesting index 18384 to 36768\u001b[0m\n",
      "\u001b[34mStarted ingesting index 0 to 18384\u001b[0m\n",
      "\u001b[34mStarted ingesting index 36768 to 55152\u001b[0m\n",
      "\u001b[34mStarted ingesting index 55152 to 73535\u001b[0m\n",
      "\u001b[35mSuccessfully ingested row 94776 to 103392\u001b[0m\n",
      "\u001b[35mSuccessfully ingested row 17232 to 25848\u001b[0m\n",
      "\u001b[35mSuccessfully ingested row 137856 to 146472\u001b[0m\n",
      "\u001b[35mSuccessfully ingested row 318792 to 327408\u001b[0m\n",
      "\u001b[35mSuccessfully ingested row 120624 to 129240\u001b[0m\n",
      "\u001b[35mSuccessfully ingested row 396336 to 404952\u001b[0m\n",
      "\u001b[35mSuccessfully ingested row 284328 to 292944\u001b[0m\n",
      "\u001b[35mSuccessfully ingested row 155088 to 163704\u001b[0m\n",
      "\u001b[35mSuccessfully ingested row 499728 to 508344\u001b[0m\n",
      "\u001b[35mSuccessfully ingested row 516960 to 525576\u001b[0m\n",
      "\u001b[35mSuccessfully ingested row 43080 to 51696\u001b[0m\n",
      "\u001b[35mSuccessfully ingested row 387720 to 396336\u001b[0m\n",
      "\u001b[35mSuccessfully ingested row 189552 to 198168\u001b[0m\n",
      "\u001b[35mSuccessfully ingested row 224016 to 232632\u001b[0m\n",
      "\u001b[35mSuccessfully ingested row 292944 to 301560\u001b[0m\n",
      "\u001b[35mSuccessfully ingested row 258480 to 267096\u001b[0m\n",
      "\u001b[35mSuccessfully ingested row 448032 to 456648\u001b[0m\n",
      "\u001b[35mSuccessfully ingested row 430800 to 439416\u001b[0m\n",
      "\u001b[35mSuccessfully ingested row 25848 to 34464\u001b[0m\n",
      "\u001b[35mSuccessfully ingested row 8616 to 17232\u001b[0m\n",
      "\u001b[35mSuccessfully ingested row 508344 to 516960\u001b[0m\n",
      "\u001b[35mSuccessfully ingested row 60312 to 68928\u001b[0m\n",
      "\u001b[35mSuccessfully ingested row 542808 to 551424\u001b[0m\n",
      "\u001b[35mSuccessfully ingested row 206784 to 215400\u001b[0m\n",
      "\u001b[35mSuccessfully ingested row 482496 to 491112\u001b[0m\n",
      "\u001b[35mSuccessfully ingested row 465264 to 473880\u001b[0m\n",
      "\u001b[35mSuccessfully ingested row 249864 to 258480\u001b[0m\n",
      "\u001b[35mSuccessfully ingested row 404952 to 413568\u001b[0m\n",
      "\u001b[35mSuccessfully ingested row 370488 to 379104\u001b[0m\n",
      "\u001b[35mSuccessfully ingested row 344640 to 353256\u001b[0m\n",
      "\u001b[35mSuccessfully ingested row 51696 to 60312\u001b[0m\n",
      "\u001b[35mSuccessfully ingested row 525576 to 534192\u001b[0m\n",
      "\u001b[35mSuccessfully ingested row 361872 to 370488\u001b[0m\n",
      "\u001b[35mSuccessfully ingested row 68928 to 77544\u001b[0m\n",
      "\u001b[35mSuccessfully ingested row 473880 to 482496\u001b[0m\n",
      "\u001b[35mSuccessfully ingested row 310176 to 318792\u001b[0m\n",
      "\u001b[35mSuccessfully ingested row 301560 to 310176\u001b[0m\n",
      "\u001b[35mSuccessfully ingested row 439416 to 448032\u001b[0m\n",
      "\u001b[35mSuccessfully ingested row 77544 to 86160\u001b[0m\n",
      "\u001b[35mSuccessfully ingested row 456648 to 465264\u001b[0m\n",
      "\u001b[35mSuccessfully ingested row 103392 to 112008\u001b[0m\n",
      "\u001b[35mSuccessfully ingested row 534192 to 542808\u001b[0m\n",
      "\u001b[35mSuccessfully ingested row 275712 to 284328\u001b[0m\n",
      "\u001b[35mSuccessfully ingested row 34464 to 43080\u001b[0m\n",
      "\u001b[35mSuccessfully ingested row 198168 to 206784\u001b[0m\n",
      "\u001b[35mSuccessfully ingested row 0 to 8616\u001b[0m\n",
      "\u001b[35mSuccessfully ingested row 491112 to 499728\u001b[0m\n",
      "\u001b[35mSuccessfully ingested row 422184 to 430800\u001b[0m\n",
      "\u001b[35mSuccessfully ingested row 172320 to 180936\u001b[0m\n",
      "\u001b[35mSuccessfully ingested row 379104 to 387720\u001b[0m\n",
      "\u001b[35mSuccessfully ingested row 232632 to 241248\u001b[0m\n",
      "\u001b[35mSuccessfully ingested row 163704 to 172320\u001b[0m\n",
      "\u001b[35mSuccessfully ingested row 267096 to 275712\u001b[0m\n",
      "\u001b[35mSuccessfully ingested row 146472 to 155088\u001b[0m\n",
      "\u001b[35mSuccessfully ingested row 86160 to 94776\u001b[0m\n",
      "\u001b[35mSuccessfully ingested row 327408 to 336024\u001b[0m\n",
      "\u001b[35mSuccessfully ingested row 215400 to 224016\u001b[0m\n",
      "\u001b[35mSuccessfully ingested row 413568 to 422184\u001b[0m\n",
      "\u001b[35mSuccessfully ingested row 353256 to 361872\u001b[0m\n",
      "\u001b[35mSuccessfully ingested row 336024 to 344640\u001b[0m\n",
      "\u001b[35mSuccessfully ingested row 180936 to 189552\u001b[0m\n",
      "\u001b[35mSuccessfully ingested row 129240 to 137856\u001b[0m\n",
      "\u001b[35mSuccessfully ingested row 112008 to 120624\u001b[0m\n",
      "\u001b[35mSuccessfully ingested row 241248 to 249864\u001b[0m\n",
      "\u001b[35mDone\u001b[0m\n",
      "\u001b[34mSuccessfully ingested row 735390 to 753775\u001b[0m\n",
      "\u001b[34mSuccessfully ingested row 569928 to 588312\u001b[0m\n",
      "\u001b[34mSuccessfully ingested row 606697 to 625082\u001b[0m\n",
      "\u001b[34mSuccessfully ingested row 110309 to 128694\u001b[0m\n",
      "\u001b[34mSuccessfully ingested row 1047931 to 1066316\u001b[0m\n",
      "\u001b[34mSuccessfully ingested row 459619 to 478004\u001b[0m\n",
      "\u001b[34mSuccessfully ingested row 165463 to 183848\u001b[0m\n",
      "\u001b[34mSuccessfully ingested row 661851 to 680236\u001b[0m\n",
      "\u001b[34mSuccessfully ingested row 956007 to 974392\u001b[0m\n",
      "\u001b[34mSuccessfully ingested row 1139853 to 1158237\u001b[0m\n",
      "\u001b[34mSuccessfully ingested row 441234 to 459619\u001b[0m\n",
      "\u001b[34mSuccessfully ingested row 0 to 18385\u001b[0m\n",
      "\u001b[34mSuccessfully ingested row 478004 to 496389\u001b[0m\n",
      "\u001b[34mSuccessfully ingested row 55155 to 73539\u001b[0m\n",
      "\u001b[34mSuccessfully ingested row 680236 to 698621\u001b[0m\n",
      "\u001b[34mSuccessfully ingested row 882468 to 900853\u001b[0m\n",
      "\u001b[34mSuccessfully ingested row 128694 to 147078\u001b[0m\n",
      "\u001b[34mSuccessfully ingested row 257387 to 275772\u001b[0m\n",
      "\u001b[34mSuccessfully ingested row 974392 to 992777\u001b[0m\n",
      "\u001b[34mSuccessfully ingested row 1011162 to 1029546\u001b[0m\n",
      "\u001b[34mSuccessfully ingested row 919238 to 937623\u001b[0m\n",
      "\u001b[34mSuccessfully ingested row 808929 to 827314\u001b[0m\n",
      "\u001b[34mSuccessfully ingested row 349311 to 367695\u001b[0m\n",
      "\u001b[34mSuccessfully ingested row 1066316 to 1084701\u001b[0m\n",
      "\u001b[34mSuccessfully ingested row 698621 to 717006\u001b[0m\n",
      "\u001b[34mSuccessfully ingested row 386080 to 404465\u001b[0m\n",
      "\u001b[34mSuccessfully ingested row 992777 to 1011162\u001b[0m\n",
      "\u001b[34mSuccessfully ingested row 1084701 to 1103085\u001b[0m\n",
      "\u001b[34mSuccessfully ingested row 202233 to 220617\u001b[0m\n",
      "\u001b[34mSuccessfully ingested row 367695 to 386080\u001b[0m\n",
      "\u001b[34mSuccessfully ingested row 294156 to 312541\u001b[0m\n",
      "\u001b[34mSuccessfully ingested row 1121469 to 1139853\u001b[0m\n",
      "\u001b[34mSuccessfully ingested row 73539 to 91924\u001b[0m\n",
      "\u001b[34mSuccessfully ingested row 220617 to 239002\u001b[0m\n",
      "\u001b[34mSuccessfully ingested row 790545 to 808929\u001b[0m\n",
      "\u001b[34mSuccessfully ingested row 864084 to 882468\u001b[0m\n",
      "\u001b[34mSuccessfully ingested row 496389 to 514773\u001b[0m\n",
      "\u001b[34mSuccessfully ingested row 239002 to 257387\u001b[0m\n",
      "\u001b[34mSuccessfully ingested row 753775 to 772160\u001b[0m\n",
      "\u001b[34mSuccessfully ingested row 312541 to 330926\u001b[0m\n",
      "\u001b[34mSuccessfully ingested row 588312 to 606697\u001b[0m\n",
      "\u001b[34mSuccessfully ingested row 533158 to 551543\u001b[0m\n",
      "\u001b[34mSuccessfully ingested row 422850 to 441234\u001b[0m\n",
      "\u001b[34mSuccessfully ingested row 404465 to 422850\u001b[0m\n",
      "\u001b[34mSuccessfully ingested row 827314 to 845699\u001b[0m\n",
      "\u001b[34mSuccessfully ingested row 91924 to 110309\u001b[0m\n",
      "\u001b[34mSuccessfully ingested row 1103085 to 1121469\u001b[0m\n",
      "\u001b[34mSuccessfully ingested row 36770 to 55155\u001b[0m\n",
      "\u001b[34mSuccessfully ingested row 717006 to 735390\u001b[0m\n",
      "\u001b[34mSuccessfully ingested row 1029546 to 1047931\u001b[0m\n",
      "\u001b[34mSuccessfully ingested row 514773 to 533158\u001b[0m\n",
      "\u001b[34mSuccessfully ingested row 937623 to 956007\u001b[0m\n",
      "\u001b[34mSuccessfully ingested row 643467 to 661851\u001b[0m\n",
      "\u001b[34mSuccessfully ingested row 845699 to 864084\u001b[0m\n",
      "\u001b[34mSuccessfully ingested row 551543 to 569928\u001b[0m\n",
      "\u001b[34mSuccessfully ingested row 900853 to 919238\u001b[0m\n",
      "\u001b[34mSuccessfully ingested row 183848 to 202233\u001b[0m\n",
      "\u001b[34mSuccessfully ingested row 625082 to 643467\u001b[0m\n",
      "\u001b[34mSuccessfully ingested row 275772 to 294156\u001b[0m\n",
      "\u001b[34mSuccessfully ingested row 330926 to 349311\u001b[0m\n",
      "\u001b[34mSuccessfully ingested row 18385 to 36770\u001b[0m\n",
      "\u001b[34mSuccessfully ingested row 1158237 to 1176620\u001b[0m\n",
      "\u001b[34mSuccessfully ingested row 772160 to 790545\u001b[0m\n",
      "\u001b[34mSuccessfully ingested row 147078 to 165463\u001b[0m\n",
      "\u001b[34mDone\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# cell 08\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "\n",
    "sklearn_processor = SKLearnProcessor(\n",
    "    framework_version=\"0.23-1\",\n",
    "    role=get_execution_role(),\n",
    "    instance_type=\"ml.m5.4xlarge\",\n",
    "    instance_count=2, \n",
    "    base_job_name='sm-immday-skprocessing'\n",
    ")\n",
    "\n",
    "sklearn_processor.run(\n",
    "    code='preprocess.py',\n",
    "    arguments = ['--fg_name', tripfare_feature_group_name,\n",
    "                 '--region', region,\n",
    "                 '--bucket', bucket,\n",
    "                ],\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source=input_data,\n",
    "            destination=\"/opt/ml/processing/input/data\",\n",
    "            s3_data_distribution_type=\"ShardedByS3Key\",\n",
    "        ),\n",
    "        ProcessingInput(\n",
    "            source=input_zones,\n",
    "            destination=\"/opt/ml/processing/input/zones\",\n",
    "            s3_data_distribution_type=\"FullyReplicated\",\n",
    "        ),\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"train\", source=\"/opt/ml/processing/train\", destination=train_path),\n",
    "        ProcessingOutput(output_name=\"validation\", source=\"/opt/ml/processing/validation\", destination=validation_path),\n",
    "        ProcessingOutput(output_name=\"test\", source=\"/opt/ml/processing/test\", destination=test_path),\n",
    "    ]\n",
    "        \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'train_path' (str)\n",
      "Stored 'validation_path' (str)\n",
      "Stored 'test_path' (str)\n"
     ]
    }
   ],
   "source": [
    "%store train_path\n",
    "%store validation_path\n",
    "%store test_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
