{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon SageMaker Batch Transform: Associate prediction results with their corresponding input records\n",
    "_**Use SageMaker's XGBoost to train a binary classification model and for a list of tumors in batch file, predict if each is malignant**_\n",
    "\n",
    "_**It also shows how to use the input output joining / filter feature in Batch transform in details**_\n",
    "\n",
    "---\n",
    "\n",
    "## Setup\n",
    "\n",
    "Let's start by specifying:\n",
    "\n",
    "* The SageMaker role arn used to give training and batch transform access to your data. The snippet below will use the same role used by your SageMaker notebook instance. Otherwise, specify the full ARN of a role with the SageMakerFullAccess policy attached.\n",
    "* The S3 bucket that you want to use for training and storing model objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from time import gmtime, strftime\n",
    "\n",
    "role = get_execution_role()\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "bucket=sagemaker.Session().default_bucket()\n",
    "prefix = 'sagemaker/DEMO-xgboost-tripfare'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/secretstorage/dhcrypto.py:16: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "/opt/conda/lib/python3.7/site-packages/secretstorage/util.py:25: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "/opt/conda/lib/python3.7/site-packages/secretstorage/dhcrypto.py:16: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "/opt/conda/lib/python3.7/site-packages/secretstorage/util.py:25: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install -Uq pip\n",
    "!python -m pip install -q awswrangler sagemaker==2.59.5 boto3==1.18.51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored variables and their in-db values:\n",
      "model_url                     -> 's3://sagemaker-us-east-1-631450739534/sagemaker/D\n",
      "test_path                     -> 's3://sagemaker-us-east-1-631450739534/sagemaker/D\n",
      "train_path                    -> 's3://sagemaker-us-east-1-631450739534/sagemaker/D\n",
      "training_job_name             -> 'DEMO-xgboost-tripfare-train-2021-09-30-03-08-58-4\n",
      "validation_path               -> 's3://sagemaker-us-east-1-631450739534/sagemaker/D\n"
     ]
    }
   ],
   "source": [
    "%store\n",
    "%store -r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  XGBoost Bring Your Own Model\n",
    "\n",
    "Amazon SageMaker includes functionality to support a hosted notebook environment, distributed, serverless training, and real-time hosting. We think it works best when all three of these services are used together, but they can also be used independently. Some use cases may only require hosting. Maybe the model was trained prior to Amazon SageMaker existing, in a different service.\n",
    "\n",
    "This section shows how to use a pre-existing trained XGBoost model with the Amazon SageMaker XGBoost Algorithm container to quickly create a hosted endpoint for that model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "container = sagemaker.image_uris.retrieve(region=boto3.Session().region_name, framework='xgboost', version='1.3-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-631450739534/sagemaker/DEMO-xgboost-tripfare/model/DEMO-xgboost-tripfare-train-2021-09-30-03-08-58-428/output/model.tar.gz\n",
      "arn:aws:sagemaker:us-east-1:631450739534:model/demo-byo-xgboost-model2021-09-30-06-08-20\n",
      "CPU times: user 62 ms, sys: 11.2 ms, total: 73.2 ms\n",
      "Wall time: 637 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_file_name = \"DEMO-byo-xgboost-model\"\n",
    "model_name = model_file_name + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "model_data = model_url\n",
    "print(model_data)\n",
    "sm_client = boto3.client(\"sagemaker\")\n",
    "\n",
    "\n",
    "primary_container = {\n",
    "    \"Image\": container,\n",
    "    \"ModelDataUrl\": model_data,\n",
    "}\n",
    "\n",
    "create_model_response2 = sm_client.create_model(\n",
    "    ModelName=model_name, ExecutionRoleArn=role, PrimaryContainer=primary_container\n",
    ")\n",
    "\n",
    "print(create_model_response2[\"ModelArn\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEMO-XGBoostEndpointConfig-2021-09-30-06-08-49\n",
      "Endpoint Config Arn: arn:aws:sagemaker:us-east-1:631450739534:endpoint-config/demo-xgboostendpointconfig-2021-09-30-06-08-49\n"
     ]
    }
   ],
   "source": [
    "endpoint_config_name = \"DEMO-XGBoostEndpointConfig-\" + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "print(endpoint_config_name)\n",
    "create_endpoint_config_response = sm_client.create_endpoint_config(\n",
    "    EndpointConfigName=endpoint_config_name,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            \"InstanceType\": \"ml.m4.xlarge\",\n",
    "            \"InitialInstanceCount\": 1,\n",
    "            \"InitialVariantWeight\": 1,\n",
    "            \"ModelName\": model_name,\n",
    "            \"VariantName\": \"AllTraffic\",\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(\"Endpoint Config Arn: \" + create_endpoint_config_response[\"EndpointConfigArn\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BYOM-XGBoostEndpoint-2021-09-30-06-09-09\n",
      "arn:aws:sagemaker:us-east-1:631450739534:endpoint/byom-xgboostendpoint-2021-09-30-06-09-09\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: InService\n",
      "Arn: arn:aws:sagemaker:us-east-1:631450739534:endpoint/byom-xgboostendpoint-2021-09-30-06-09-09\n",
      "Status: InService\n",
      "CPU times: user 130 ms, sys: 29.2 ms, total: 159 ms\n",
      "Wall time: 10min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import time\n",
    "\n",
    "endpoint_name = \"BYOM-XGBoostEndpoint-\" + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "print(endpoint_name)\n",
    "create_endpoint_response = sm_client.create_endpoint(\n",
    "    EndpointName=endpoint_name, EndpointConfigName=endpoint_config_name\n",
    ")\n",
    "print(create_endpoint_response[\"EndpointArn\"])\n",
    "\n",
    "resp = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "status = resp[\"EndpointStatus\"]\n",
    "print(\"Status: \" + status)\n",
    "\n",
    "while status == \"Creating\":\n",
    "    time.sleep(60)\n",
    "    resp = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "    status = resp[\"EndpointStatus\"]\n",
    "    print(\"Status: \" + status)\n",
    "\n",
    "print(\"Arn: \" + resp[\"EndpointArn\"])\n",
    "print(\"Status: \" + status)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import awswrangler as wr\n",
    "test_df = wr.s3.read_csv(\n",
    "        path=test_path, dataset=True, nrows=5, header=None\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class Probabilities: 18.545743942260742,6.25778341293335,19.946535110473633,26.39051055908203,7.497164726257324,17.29636573791504,11.487503051757812,35.032718658447266,18.201818466186523,8.741583824157715.\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import csv\n",
    "\n",
    "runtime_client = boto3.client(\"runtime.sagemaker\")\n",
    "\n",
    "data = test_df.iloc[:,1:].to_numpy()\n",
    "\n",
    "results = []\n",
    "csv_buffer = io.StringIO()\n",
    "csv_writer = csv.writer(csv_buffer, delimiter=\",\")\n",
    "for record in data:\n",
    "    csv_writer.writerow(record)\n",
    "\n",
    "response = runtime_client.invoke_endpoint(\n",
    "        EndpointName=endpoint_name, ContentType=\"text/csv\", Body=csv_buffer.getvalue()\n",
    "    )\n",
    "print(\"Predicted Class Probabilities: {}.\".format(response[\"Body\"].read().decode(\"ascii\")))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Transform\n",
    "\n",
    "\n",
    "In SageMaker Batch Transform, we introduced 3 new attributes - __input_filter__, __join_source__ and __output_filter__. In the below cell, we use the [SageMaker Python SDK](https://github.com/aws/sagemaker-python-sdk) to kick-off several Batch Transform jobs using different configurations of these 3 new attributes. Please refer to [this page](https://docs.aws.amazon.com/sagemaker/latest/dg/batch-transform-data-processing.html) to learn more about how to use them.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Create a transform job with the default configurations\n",
    "Let's first skip these 3 new attributes and inspect the inference results. We'll use it as a baseline to compare to the results with data processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.model import Model\n",
    "xgb_model = Model(\n",
    "    image_uri=container,\n",
    "    model_data=model_url,\n",
    "    role=role,\n",
    "    name=model_file_name + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime()),\n",
    "    sagemaker_session=sagemaker_session,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Join the input and the prediction results \n",
    "Now, let's associate the prediction results with their corresponding input records. We can also use the __input_filter__ to exclude the ID column easily and there's no need to have a separate file in S3.\n",
    "\n",
    "* Set __input_filter__ to \"$[1:]\": indicates that we are excluding column 0 (the 'ID') before processing the inferences and keeping everything from column 1 to the last column (all the features or predictors)  \n",
    "  \n",
    "  \n",
    "* Set __join_source__ to \"Input\": indicates our desire to join the input data with the inference results  \n",
    "\n",
    "* Leave __output_filter__ to default ('$'), indicating that the joined input and inference results be will saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using already existing model: DEMO-byo-xgboost-model2021-09-30-06-47-15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..................................\u001b[35m[2021-09-30:06:57:24:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2021-09-30:06:57:24:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2021-09-30:06:57:24:INFO] nginx config: \u001b[0m\n",
      "\u001b[35mworker_processes auto;\u001b[0m\n",
      "\u001b[35mdaemon off;\u001b[0m\n",
      "\u001b[35mpid /tmp/nginx.pid;\u001b[0m\n",
      "\u001b[35merror_log  /dev/stderr;\n",
      "\u001b[0m\n",
      "\u001b[35mworker_rlimit_nofile 4096;\n",
      "\u001b[0m\n",
      "\u001b[35mevents {\n",
      "  worker_connections 2048;\u001b[0m\n",
      "\u001b[35m}\n",
      "\u001b[0m\n",
      "\u001b[35mhttp {\n",
      "  include /etc/nginx/mime.types;\n",
      "  default_type application/octet-stream;\n",
      "  access_log /dev/stdout combined;\n",
      "\n",
      "  upstream gunicorn {\n",
      "    server unix:/tmp/gunicorn.sock;\n",
      "  }\n",
      "\n",
      "  server {\n",
      "    listen 8080 deferred;\n",
      "    client_max_body_size 0;\n",
      "\n",
      "    keepalive_timeout 3;\n",
      "\n",
      "    location ~ ^/(ping|invocations|execution-parameters) {\n",
      "      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
      "      proxy_set_header Host $http_host;\n",
      "      proxy_redirect off;\n",
      "      proxy_read_timeout 60s;\n",
      "      proxy_pass http://gunicorn;\n",
      "    }\n",
      "\n",
      "    location / {\n",
      "      return 404 \"{}\";\n",
      "    }\n",
      "\n",
      "  }\u001b[0m\n",
      "\u001b[35m}\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[35m[2021-09-30 06:57:24 +0000] [20] [INFO] Starting gunicorn 19.10.0\u001b[0m\n",
      "\u001b[35m[2021-09-30 06:57:24 +0000] [20] [INFO] Listening at: unix:/tmp/gunicorn.sock (20)\u001b[0m\n",
      "\u001b[35m[2021-09-30 06:57:24 +0000] [20] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[35m[2021-09-30 06:57:24 +0000] [27] [INFO] Booting worker with pid: 27\u001b[0m\n",
      "\u001b[35m[2021-09-30 06:57:24 +0000] [28] [INFO] Booting worker with pid: 28\u001b[0m\n",
      "\u001b[35m[2021-09-30 06:57:24 +0000] [32] [INFO] Booting worker with pid: 32\u001b[0m\n",
      "\u001b[35m[2021-09-30 06:57:24 +0000] [33] [INFO] Booting worker with pid: 33\u001b[0m\n",
      "\u001b[35m[2021-09-30:06:57:26:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2021-09-30:06:57:26:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[35m[2021-09-30:06:57:26:INFO] Model objective : reg:squarederror\u001b[0m\n",
      "\u001b[35m[2021-09-30:06:57:26:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2021-09-30:06:57:26:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[35m[2021-09-30:06:57:26:INFO] Model objective : reg:squarederror\u001b[0m\n",
      "\u001b[35m[2021-09-30:06:57:26:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2021-09-30:06:57:26:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[35m[2021-09-30:06:57:26:INFO] Model objective : reg:squarederror\u001b[0m\n",
      "\u001b[35m[2021-09-30:06:57:26:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2021-09-30:06:57:26:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[35m[2021-09-30:06:57:26:INFO] Model objective : reg:squarederror\u001b[0m\n",
      "\u001b[34m[2021-09-30:06:57:29:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2021-09-30:06:57:29:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2021-09-30:06:57:29:INFO] nginx config: \u001b[0m\n",
      "\u001b[34mworker_processes auto;\u001b[0m\n",
      "\u001b[34mdaemon off;\u001b[0m\n",
      "\u001b[34mpid /tmp/nginx.pid;\u001b[0m\n",
      "\u001b[34merror_log  /dev/stderr;\n",
      "\u001b[0m\n",
      "\u001b[34mworker_rlimit_nofile 4096;\n",
      "\u001b[0m\n",
      "\u001b[34mevents {\n",
      "  worker_connections 2048;\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mhttp {\n",
      "  include /etc/nginx/mime.types;\n",
      "  default_type application/octet-stream;\n",
      "  access_log /dev/stdout combined;\n",
      "\n",
      "  upstream gunicorn {\n",
      "    server unix:/tmp/gunicorn.sock;\n",
      "  }\n",
      "\n",
      "  server {\n",
      "    listen 8080 deferred;\n",
      "    client_max_body_size 0;\n",
      "\n",
      "    keepalive_timeout 3;\n",
      "\n",
      "    location ~ ^/(ping|invocations|execution-parameters) {\n",
      "      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
      "      proxy_set_header Host $http_host;\n",
      "      proxy_redirect off;\n",
      "      proxy_read_timeout 60s;\n",
      "      proxy_pass http://gunicorn;\n",
      "    }\n",
      "\n",
      "    location / {\n",
      "      return 404 \"{}\";\n",
      "    }\n",
      "\n",
      "  }\u001b[0m\n",
      "\u001b[34m}\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34m[2021-09-30 06:57:29 +0000] [19] [INFO] Starting gunicorn 19.10.0\u001b[0m\n",
      "\u001b[34m[2021-09-30 06:57:29 +0000] [19] [INFO] Listening at: unix:/tmp/gunicorn.sock (19)\u001b[0m\n",
      "\u001b[34m[2021-09-30 06:57:29 +0000] [19] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m[2021-09-30 06:57:29 +0000] [26] [INFO] Booting worker with pid: 26\u001b[0m\n",
      "\u001b[34m[2021-09-30 06:57:29 +0000] [27] [INFO] Booting worker with pid: 27\u001b[0m\n",
      "\u001b[34m[2021-09-30 06:57:29 +0000] [28] [INFO] Booting worker with pid: 28\u001b[0m\n",
      "\u001b[34m[2021-09-30 06:57:29 +0000] [29] [INFO] Booting worker with pid: 29\u001b[0m\n",
      "\u001b[34m[2021-09-30:06:57:31:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2021-09-30:06:57:31:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[34m[2021-09-30:06:57:31:INFO] Model objective : reg:squarederror\u001b[0m\n",
      "\u001b[34m[2021-09-30:06:57:31:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2021-09-30:06:57:31:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[34m[2021-09-30:06:57:31:INFO] Model objective : reg:squarederror\u001b[0m\n",
      "\u001b[34m[2021-09-30:06:57:31:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2021-09-30:06:57:31:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[34m[2021-09-30:06:57:31:INFO] Model objective : reg:squarederror\u001b[0m\n",
      "\u001b[34m[2021-09-30:06:57:31:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2021-09-30:06:57:31:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[34m[2021-09-30:06:57:31:INFO] Model objective : reg:squarederror\u001b[0m\n",
      "\u001b[34m[2021-09-30:06:57:35:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [30/Sep/2021:06:57:35 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [30/Sep/2021:06:57:35 +0000] \"GET /execution-parameters HTTP/1.1\" 200 84 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m[2021-09-30:06:57:35:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2021-09-30:06:57:35:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35m[2021-09-30:06:57:36:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [30/Sep/2021:06:57:36 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m[2021-09-30:06:57:36:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [30/Sep/2021:06:57:36 +0000] \"GET /execution-parameters HTTP/1.1\" 200 84 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [30/Sep/2021:06:57:36 +0000] \"POST /invocations HTTP/1.1\" 200 216328 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m[2021-09-30:06:57:37:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2021-09-30:06:57:37:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [30/Sep/2021:06:57:37 +0000] \"POST /invocations HTTP/1.1\" 200 101445 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2021-09-30T06:57:36.797:[sagemaker logs]: MaxConcurrentTransforms=4, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[35m2021-09-30T06:57:35.574:[sagemaker logs]: MaxConcurrentTransforms=4, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[36m2021-09-30T06:57:35.574:[sagemaker logs]: MaxConcurrentTransforms=4, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\n",
      "\u001b[33m[2021-09-30:06:57:24:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[33m[2021-09-30:06:57:24:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[33m[2021-09-30:06:57:24:INFO] nginx config: \u001b[0m\n",
      "\u001b[33mworker_processes auto;\u001b[0m\n",
      "\u001b[33mdaemon off;\u001b[0m\n",
      "\u001b[33mpid /tmp/nginx.pid;\u001b[0m\n",
      "\u001b[33merror_log  /dev/stderr;\n",
      "\u001b[0m\n",
      "\u001b[33mworker_rlimit_nofile 4096;\n",
      "\u001b[0m\n",
      "\u001b[33mevents {\n",
      "  worker_connections 2048;\u001b[0m\n",
      "\u001b[33m}\n",
      "\u001b[0m\n",
      "\u001b[33mhttp {\n",
      "  include /etc/nginx/mime.types;\n",
      "  default_type application/octet-stream;\n",
      "  access_log /dev/stdout combined;\n",
      "\n",
      "  upstream gunicorn {\n",
      "    server unix:/tmp/gunicorn.sock;\n",
      "  }\n",
      "\n",
      "  server {\n",
      "    listen 8080 deferred;\n",
      "    client_max_body_size 0;\n",
      "\n",
      "    keepalive_timeout 3;\n",
      "\n",
      "    location ~ ^/(ping|invocations|execution-parameters) {\n",
      "      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
      "      proxy_set_header Host $http_host;\n",
      "      proxy_redirect off;\n",
      "      proxy_read_timeout 60s;\n",
      "      proxy_pass http://gunicorn;\n",
      "    }\n",
      "\n",
      "    location / {\n",
      "      return 404 \"{}\";\n",
      "    }\n",
      "\n",
      "  }\u001b[0m\n",
      "\u001b[33m}\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[33m[2021-09-30 06:57:24 +0000] [20] [INFO] Starting gunicorn 19.10.0\u001b[0m\n",
      "\u001b[33m[2021-09-30 06:57:24 +0000] [20] [INFO] Listening at: unix:/tmp/gunicorn.sock (20)\u001b[0m\n",
      "\u001b[33m[2021-09-30 06:57:24 +0000] [20] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[33m[2021-09-30 06:57:24 +0000] [27] [INFO] Booting worker with pid: 27\u001b[0m\n",
      "\u001b[33m[2021-09-30 06:57:24 +0000] [28] [INFO] Booting worker with pid: 28\u001b[0m\n",
      "\u001b[33m[2021-09-30 06:57:24 +0000] [32] [INFO] Booting worker with pid: 32\u001b[0m\n",
      "\u001b[33m[2021-09-30 06:57:24 +0000] [33] [INFO] Booting worker with pid: 33\u001b[0m\n",
      "\u001b[33m[2021-09-30:06:57:26:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[33m[2021-09-30:06:57:26:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[33m[2021-09-30:06:57:26:INFO] Model objective : reg:squarederror\u001b[0m\n",
      "\u001b[33m[2021-09-30:06:57:26:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[33m[2021-09-30:06:57:26:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[33m[2021-09-30:06:57:26:INFO] Model objective : reg:squarederror\u001b[0m\n",
      "\u001b[33m[2021-09-30:06:57:26:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[33m[2021-09-30:06:57:26:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[33m[2021-09-30:06:57:26:INFO] Model objective : reg:squarederror\u001b[0m\n",
      "\u001b[33m[2021-09-30:06:57:26:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[33m[2021-09-30:06:57:26:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[33m[2021-09-30:06:57:26:INFO] Model objective : reg:squarederror\u001b[0m\n",
      "\u001b[34m[2021-09-30:06:57:29:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2021-09-30:06:57:29:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2021-09-30:06:57:29:INFO] nginx config: \u001b[0m\n",
      "\u001b[34mworker_processes auto;\u001b[0m\n",
      "\u001b[34mdaemon off;\u001b[0m\n",
      "\u001b[34mpid /tmp/nginx.pid;\u001b[0m\n",
      "\u001b[34merror_log  /dev/stderr;\n",
      "\u001b[0m\n",
      "\u001b[34mworker_rlimit_nofile 4096;\n",
      "\u001b[0m\n",
      "\u001b[34mevents {\n",
      "  worker_connections 2048;\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[32m[2021-09-30:06:57:29:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[32m[2021-09-30:06:57:29:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[32m[2021-09-30:06:57:29:INFO] nginx config: \u001b[0m\n",
      "\u001b[32mworker_processes auto;\u001b[0m\n",
      "\u001b[32mdaemon off;\u001b[0m\n",
      "\u001b[32mpid /tmp/nginx.pid;\u001b[0m\n",
      "\u001b[32merror_log  /dev/stderr;\n",
      "\u001b[0m\n",
      "\u001b[32mworker_rlimit_nofile 4096;\n",
      "\u001b[0m\n",
      "\u001b[32mevents {\n",
      "  worker_connections 2048;\u001b[0m\n",
      "\u001b[32m}\n",
      "\u001b[0m\n",
      "\u001b[34mhttp {\n",
      "  include /etc/nginx/mime.types;\n",
      "  default_type application/octet-stream;\n",
      "  access_log /dev/stdout combined;\n",
      "\n",
      "  upstream gunicorn {\n",
      "    server unix:/tmp/gunicorn.sock;\n",
      "  }\n",
      "\n",
      "  server {\n",
      "    listen 8080 deferred;\n",
      "    client_max_body_size 0;\n",
      "\n",
      "    keepalive_timeout 3;\n",
      "\n",
      "    location ~ ^/(ping|invocations|execution-parameters) {\n",
      "      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
      "      proxy_set_header Host $http_host;\n",
      "      proxy_redirect off;\n",
      "      proxy_read_timeout 60s;\n",
      "      proxy_pass http://gunicorn;\n",
      "    }\n",
      "\n",
      "    location / {\n",
      "      return 404 \"{}\";\n",
      "    }\n",
      "\n",
      "  }\u001b[0m\n",
      "\u001b[34m}\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34m[2021-09-30 06:57:29 +0000] [19] [INFO] Starting gunicorn 19.10.0\u001b[0m\n",
      "\u001b[34m[2021-09-30 06:57:29 +0000] [19] [INFO] Listening at: unix:/tmp/gunicorn.sock (19)\u001b[0m\n",
      "\u001b[34m[2021-09-30 06:57:29 +0000] [19] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m[2021-09-30 06:57:29 +0000] [26] [INFO] Booting worker with pid: 26\u001b[0m\n",
      "\u001b[34m[2021-09-30 06:57:29 +0000] [27] [INFO] Booting worker with pid: 27\u001b[0m\n",
      "\u001b[34m[2021-09-30 06:57:29 +0000] [28] [INFO] Booting worker with pid: 28\u001b[0m\n",
      "\u001b[34m[2021-09-30 06:57:29 +0000] [29] [INFO] Booting worker with pid: 29\u001b[0m\n",
      "\u001b[34m[2021-09-30:06:57:31:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2021-09-30:06:57:31:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[34m[2021-09-30:06:57:31:INFO] Model objective : reg:squarederror\u001b[0m\n",
      "\u001b[34m[2021-09-30:06:57:31:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2021-09-30:06:57:31:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[34m[2021-09-30:06:57:31:INFO] Model objective : reg:squarederror\u001b[0m\n",
      "\u001b[34m[2021-09-30:06:57:31:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2021-09-30:06:57:31:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[32mhttp {\n",
      "  include /etc/nginx/mime.types;\n",
      "  default_type application/octet-stream;\n",
      "  access_log /dev/stdout combined;\n",
      "\n",
      "  upstream gunicorn {\n",
      "    server unix:/tmp/gunicorn.sock;\n",
      "  }\n",
      "\n",
      "  server {\n",
      "    listen 8080 deferred;\n",
      "    client_max_body_size 0;\n",
      "\n",
      "    keepalive_timeout 3;\n",
      "\n",
      "    location ~ ^/(ping|invocations|execution-parameters) {\n",
      "      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
      "      proxy_set_header Host $http_host;\n",
      "      proxy_redirect off;\n",
      "      proxy_read_timeout 60s;\n",
      "      proxy_pass http://gunicorn;\n",
      "    }\n",
      "\n",
      "    location / {\n",
      "      return 404 \"{}\";\n",
      "    }\n",
      "\n",
      "  }\u001b[0m\n",
      "\u001b[32m}\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[32m[2021-09-30 06:57:29 +0000] [19] [INFO] Starting gunicorn 19.10.0\u001b[0m\n",
      "\u001b[32m[2021-09-30 06:57:29 +0000] [19] [INFO] Listening at: unix:/tmp/gunicorn.sock (19)\u001b[0m\n",
      "\u001b[32m[2021-09-30 06:57:29 +0000] [19] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[32m[2021-09-30 06:57:29 +0000] [26] [INFO] Booting worker with pid: 26\u001b[0m\n",
      "\u001b[32m[2021-09-30 06:57:29 +0000] [27] [INFO] Booting worker with pid: 27\u001b[0m\n",
      "\u001b[32m[2021-09-30 06:57:29 +0000] [28] [INFO] Booting worker with pid: 28\u001b[0m\n",
      "\u001b[32m[2021-09-30 06:57:29 +0000] [29] [INFO] Booting worker with pid: 29\u001b[0m\n",
      "\u001b[32m[2021-09-30:06:57:31:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[32m[2021-09-30:06:57:31:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[32m[2021-09-30:06:57:31:INFO] Model objective : reg:squarederror\u001b[0m\n",
      "\u001b[32m[2021-09-30:06:57:31:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[32m[2021-09-30:06:57:31:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[32m[2021-09-30:06:57:31:INFO] Model objective : reg:squarederror\u001b[0m\n",
      "\u001b[32m[2021-09-30:06:57:31:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[32m[2021-09-30:06:57:31:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[34m[2021-09-30:06:57:31:INFO] Model objective : reg:squarederror\u001b[0m\n",
      "\u001b[34m[2021-09-30:06:57:31:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2021-09-30:06:57:31:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[34m[2021-09-30:06:57:31:INFO] Model objective : reg:squarederror\u001b[0m\n",
      "\u001b[32m[2021-09-30:06:57:31:INFO] Model objective : reg:squarederror\u001b[0m\n",
      "\u001b[32m[2021-09-30:06:57:31:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[32m[2021-09-30:06:57:31:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[32m[2021-09-30:06:57:31:INFO] Model objective : reg:squarederror\u001b[0m\n",
      "\u001b[34m[2021-09-30:06:57:35:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [30/Sep/2021:06:57:35 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [30/Sep/2021:06:57:35 +0000] \"GET /execution-parameters HTTP/1.1\" 200 84 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m[2021-09-30:06:57:35:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2021-09-30:06:57:35:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[32m[2021-09-30:06:57:35:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[32m169.254.255.130 - - [30/Sep/2021:06:57:35 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[32m169.254.255.130 - - [30/Sep/2021:06:57:35 +0000] \"GET /execution-parameters HTTP/1.1\" 200 84 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[32m[2021-09-30:06:57:35:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[32m[2021-09-30:06:57:35:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[33m[2021-09-30:06:57:36:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[33m169.254.255.130 - - [30/Sep/2021:06:57:36 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[33m[2021-09-30:06:57:36:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[33m169.254.255.130 - - [30/Sep/2021:06:57:36 +0000] \"GET /execution-parameters HTTP/1.1\" 200 84 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [30/Sep/2021:06:57:36 +0000] \"POST /invocations HTTP/1.1\" 200 216328 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[32m169.254.255.130 - - [30/Sep/2021:06:57:36 +0000] \"POST /invocations HTTP/1.1\" 200 216328 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[33m[2021-09-30:06:57:37:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[33m[2021-09-30:06:57:37:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[33m169.254.255.130 - - [30/Sep/2021:06:57:37 +0000] \"POST /invocations HTTP/1.1\" 200 101445 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2021-09-30T06:57:36.797:[sagemaker logs]: MaxConcurrentTransforms=4, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[35m2021-09-30T06:57:35.574:[sagemaker logs]: MaxConcurrentTransforms=4, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[36m2021-09-30T06:57:35.574:[sagemaker logs]: MaxConcurrentTransforms=4, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "xgb_transformer = xgb_model.transformer(instance_count=2, instance_type=\"ml.m4.xlarge\")\n",
    "\n",
    "# content_type / accept and split_type / assemble_with are required to use IO joining feature\n",
    "xgb_transformer.assemble_with = \"Line\"\n",
    "xgb_transformer.accept = \"text/csv\"\n",
    "\n",
    "# start a transform job\n",
    "xgb_transformer.transform(test_path, \n",
    "                         content_type=\"text/csv\", \n",
    "                         split_type=\"Line\",\n",
    "                         input_filter=\"$[1:]\",\n",
    "                         join_source=\"Input\",\n",
    "                        )\n",
    "xgb_transformer.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect the output of the Batch Transform job in S3. It should show the list of tumors identified by their original feature columns and their corresponding probabilities of being malignant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df = get_csv_output_from_s3(sm_transformer.output_path, batch_file)\n",
    "output_df.head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally you can update the output filter to keep only ID and prediction results. For example, you can change __output_filter__ to \"$[0,-1]\", indicating that when presenting the output, we only want to keep column 0 and the last column (the inference result i.e. the predicted trip fare)\n",
    "\n",
    "In summary, we can use newly introduced 3 attributes - __input_filter__, __join_source__, __output_filter__ to \n",
    "1. Filter / select useful features from the input dataset. e.g. exclude ID columns.\n",
    "2. Associate the prediction results with their corresponding input records.\n",
    "3. Filter the original or joined results before saving to S3. e.g. keep ID and probability columns only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
