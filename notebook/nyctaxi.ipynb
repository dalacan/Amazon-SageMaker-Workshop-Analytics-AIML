{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NYC Taxi Fare Prediction\n",
    "\n",
    "Predict taxi fares using the [New York City Taxi and Limousine Commission (TLC) Trip Record Data](https://registry.opendata.aws/nyc-tlc-trip-records-pds/) public dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install -U pandas geopandas seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Prep\n",
    " \n",
    "In this section of the notebook, you will download the publicly available New York Taxi dataset in preparation for uploading it to S3.\n",
    "\n",
    "### Download Dataset\n",
    "\n",
    "First, download a sample of the New York City Taxi [dataset](https://registry.opendata.aws/nyc-tlc-trip-records-pds/)⇗ to this notebook instance. \n",
    "\n",
    "This dataset contains information on trips taken by taxis and for-hire vehicles in New York City, including pick-up and drop-off times and locations, fares, distance traveled, and more. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://nyc-tlc/trip data/green_tripdata_2018-02.csv to ./nyc-tlc.csv\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp 's3://nyc-tlc/trip data/green_tripdata_2018-02.csv' 'nyc-tlc.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://nyc-tlc/misc/taxi_zones.zip to ./taxi_zones.zip      \n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp 's3://nyc-tlc/misc/taxi_zones.zip' 'taxi_zones.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  taxi_zones.zip\n",
      "  inflating: shapes/taxi_zones.prj   \n",
      "  inflating: shapes/taxi_zones.dbf   \n",
      "  inflating: shapes/taxi_zones.shp   \n",
      "  inflating: shapes/taxi_zones.shp.xml  \n",
      "  inflating: shapes/taxi_zones.shx   \n",
      "  inflating: shapes/taxi_zones.sbn   \n",
      "  inflating: shapes/taxi_zones.sbx   \n"
     ]
    }
   ],
   "source": [
    "!unzip taxi_zones.zip -d shapes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Datasets\n",
    "\n",
    "Load the trip dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>lpep_pickup_datetime</th>\n",
       "      <th>lpep_dropoff_datetime</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>ehail_fee</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>trip_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-02-01 00:39:38</td>\n",
       "      <td>2018-02-01 00:39:41</td>\n",
       "      <td>N</td>\n",
       "      <td>5</td>\n",
       "      <td>97</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-02-01 00:58:28</td>\n",
       "      <td>2018-02-01 01:05:35</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "      <td>80</td>\n",
       "      <td>5</td>\n",
       "      <td>1.60</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>9.68</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-02-01 00:56:05</td>\n",
       "      <td>2018-02-01 01:18:54</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>95</td>\n",
       "      <td>1</td>\n",
       "      <td>9.60</td>\n",
       "      <td>28.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5.96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>35.76</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-02-01 00:12:40</td>\n",
       "      <td>2018-02-01 00:15:50</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>61</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>0.73</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>5.80</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-02-01 00:45:18</td>\n",
       "      <td>2018-02-01 00:51:56</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>1.87</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>9.30</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VendorID lpep_pickup_datetime lpep_dropoff_datetime store_and_fwd_flag  \\\n",
       "0         2  2018-02-01 00:39:38   2018-02-01 00:39:41                  N   \n",
       "1         2  2018-02-01 00:58:28   2018-02-01 01:05:35                  N   \n",
       "2         2  2018-02-01 00:56:05   2018-02-01 01:18:54                  N   \n",
       "3         2  2018-02-01 00:12:40   2018-02-01 00:15:50                  N   \n",
       "4         2  2018-02-01 00:45:18   2018-02-01 00:51:56                  N   \n",
       "\n",
       "   RatecodeID  PULocationID  DOLocationID  passenger_count  trip_distance  \\\n",
       "0           5            97            65                1           0.00   \n",
       "1           1           256            80                5           1.60   \n",
       "2           1            25            95                1           9.60   \n",
       "3           1            61            61                1           0.73   \n",
       "4           1            65            17                2           1.87   \n",
       "\n",
       "   fare_amount  extra  mta_tax  tip_amount  tolls_amount  ehail_fee  \\\n",
       "0         20.0    0.0      0.0        3.00           0.0        NaN   \n",
       "1          7.5    0.5      0.5        0.88           0.0        NaN   \n",
       "2         28.5    0.5      0.5        5.96           0.0        NaN   \n",
       "3          4.5    0.5      0.5        0.00           0.0        NaN   \n",
       "4          8.0    0.5      0.5        0.00           0.0        NaN   \n",
       "\n",
       "   improvement_surcharge  total_amount  payment_type  trip_type  \n",
       "0                    0.0         23.00             1          2  \n",
       "1                    0.3          9.68             1          1  \n",
       "2                    0.3         35.76             1          1  \n",
       "3                    0.3          5.80             2          1  \n",
       "4                    0.3          9.30             2          1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "trip_df = pd.read_csv(\n",
    "    \"nyc-tlc.csv\", parse_dates=[\"lpep_pickup_datetime\", \"lpep_dropoff_datetime\"]\n",
    ")\n",
    "trip_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the taxi zone shape data to get the gemotry and calculate a centroid and lat/long  each location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zone</th>\n",
       "      <th>borough</th>\n",
       "      <th>geometry</th>\n",
       "      <th>centroid</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LocationID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Newark Airport</td>\n",
       "      <td>EWR</td>\n",
       "      <td>POLYGON ((933100.918 192536.086, 933091.011 19...</td>\n",
       "      <td>POINT (3725166.680 1215524.288)</td>\n",
       "      <td>-74.174002</td>\n",
       "      <td>40.691830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jamaica Bay</td>\n",
       "      <td>Queens</td>\n",
       "      <td>MULTIPOLYGON (((1033269.244 172126.008, 103343...</td>\n",
       "      <td>POINT (3754697.301 1221668.447)</td>\n",
       "      <td>-73.831300</td>\n",
       "      <td>40.616746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Allerton/Pelham Gardens</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>POLYGON ((1026308.770 256767.698, 1026495.593 ...</td>\n",
       "      <td>POINT (3740625.705 1245337.966)</td>\n",
       "      <td>-73.847422</td>\n",
       "      <td>40.864474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alphabet City</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>POLYGON ((992073.467 203714.076, 992068.667 20...</td>\n",
       "      <td>POINT (3738254.502 1226415.990)</td>\n",
       "      <td>-73.976968</td>\n",
       "      <td>40.723752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Arden Heights</td>\n",
       "      <td>Staten Island</td>\n",
       "      <td>POLYGON ((935843.310 144283.336, 936046.565 14...</td>\n",
       "      <td>POINT (3731261.945 1201271.914)</td>\n",
       "      <td>-74.188485</td>\n",
       "      <td>40.552659</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               zone        borough  \\\n",
       "LocationID                                           \n",
       "1                    Newark Airport            EWR   \n",
       "2                       Jamaica Bay         Queens   \n",
       "3           Allerton/Pelham Gardens          Bronx   \n",
       "4                     Alphabet City      Manhattan   \n",
       "5                     Arden Heights  Staten Island   \n",
       "\n",
       "                                                     geometry  \\\n",
       "LocationID                                                      \n",
       "1           POLYGON ((933100.918 192536.086, 933091.011 19...   \n",
       "2           MULTIPOLYGON (((1033269.244 172126.008, 103343...   \n",
       "3           POLYGON ((1026308.770 256767.698, 1026495.593 ...   \n",
       "4           POLYGON ((992073.467 203714.076, 992068.667 20...   \n",
       "5           POLYGON ((935843.310 144283.336, 936046.565 14...   \n",
       "\n",
       "                                   centroid   latitude  longitude  \n",
       "LocationID                                                         \n",
       "1           POINT (3725166.680 1215524.288) -74.174002  40.691830  \n",
       "2           POINT (3754697.301 1221668.447) -73.831300  40.616746  \n",
       "3           POINT (3740625.705 1245337.966) -73.847422  40.864474  \n",
       "4           POINT (3738254.502 1226415.990) -73.976968  40.723752  \n",
       "5           POINT (3731261.945 1201271.914) -74.188485  40.552659  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "# Load the shape file and get the geometry and lat/lon\n",
    "zones = gpd.read_file(\"shapes/taxi_zones.shp\")\n",
    "# Return Centroid as CRS code of 3310 for calcuating distance in meters.\n",
    "zones[\"centroid\"] = zones.geometry.centroid.to_crs(epsg=3310)\n",
    "# Convert cordinates to the WSG84 lat/long CRS has a EPSG code of 4326.\n",
    "zones[\"latitude\"] = zones.centroid.to_crs(epsg=4326).x\n",
    "zones[\"longitude\"] = zones.centroid.to_crs(epsg=4326).y\n",
    "\n",
    "# Drop duplicate by location ID keeping the first\n",
    "zones = zones.drop_duplicates(subset=\"LocationID\", keep=\"first\")\n",
    "# Drop cols we don't need and inspect results\n",
    "zones = zones.set_index(\"LocationID\").drop(\n",
    "    [\"OBJECTID\", \"Shape_Leng\", \"Shape_Area\"], axis=1\n",
    ")\n",
    "zones.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join the trip data to the zone and calculate the distance between centroids (should take < 20 seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.84 s, sys: 185 ms, total: 6.03 s\n",
      "Wall time: 6.28 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>geo_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>97</td>\n",
       "      <td>65</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.073533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>256</td>\n",
       "      <td>80</td>\n",
       "      <td>1.60</td>\n",
       "      <td>2.015894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25</td>\n",
       "      <td>95</td>\n",
       "      <td>9.60</td>\n",
       "      <td>12.359122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61</td>\n",
       "      <td>61</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>65</td>\n",
       "      <td>17</td>\n",
       "      <td>1.87</td>\n",
       "      <td>3.088219</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PULocationID  DOLocationID  trip_distance  geo_distance\n",
       "0            97            65           0.00      1.073533\n",
       "1           256            80           1.60      2.015894\n",
       "2            25            95           9.60     12.359122\n",
       "3            61            61           0.73      0.000000\n",
       "4            65            17           1.87      3.088219"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "trip_df = gpd.GeoDataFrame(\n",
    "    trip_df.join(zones, on=\"PULocationID\").join(\n",
    "        zones, on=\"DOLocationID\", rsuffix=\"_DO\", lsuffix=\"_PU\"\n",
    "    )\n",
    ")\n",
    "trip_df[\"geo_distance\"] = trip_df[\"centroid_PU\"].distance(trip_df[\"centroid_DO\"]) / 1000\n",
    "trip_df[[\"PULocationID\", \"DOLocationID\", \"trip_distance\", \"geo_distance\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>lpep_pickup_datetime</th>\n",
       "      <th>lpep_dropoff_datetime</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>ehail_fee</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>trip_type</th>\n",
       "      <th>zone_PU</th>\n",
       "      <th>borough_PU</th>\n",
       "      <th>geometry_PU</th>\n",
       "      <th>centroid_PU</th>\n",
       "      <th>latitude_PU</th>\n",
       "      <th>longitude_PU</th>\n",
       "      <th>zone_DO</th>\n",
       "      <th>borough_DO</th>\n",
       "      <th>geometry_DO</th>\n",
       "      <th>centroid_DO</th>\n",
       "      <th>latitude_DO</th>\n",
       "      <th>longitude_DO</th>\n",
       "      <th>geo_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-02-01 00:39:38</td>\n",
       "      <td>2018-02-01 00:39:41</td>\n",
       "      <td>N</td>\n",
       "      <td>5</td>\n",
       "      <td>97</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Fort Greene</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>POLYGON ((992751.699 192765.140, 992899.310 19...</td>\n",
       "      <td>POINT (3740118.202 1223261.158)</td>\n",
       "      <td>-73.974882</td>\n",
       "      <td>40.690787</td>\n",
       "      <td>Downtown Brooklyn/MetroTech</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>POLYGON ((987819.980 194536.761, 987838.631 19...</td>\n",
       "      <td>POINT (3739044.681 1223266.137)</td>\n",
       "      <td>-73.986086</td>\n",
       "      <td>40.695337</td>\n",
       "      <td>1.073533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-02-01 00:58:28</td>\n",
       "      <td>2018-02-01 01:05:35</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "      <td>80</td>\n",
       "      <td>5</td>\n",
       "      <td>1.60</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>9.68</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Williamsburg (South Side)</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>POLYGON ((995798.638 199155.970, 996223.601 19...</td>\n",
       "      <td>POINT (3740196.862 1225825.044)</td>\n",
       "      <td>-73.959905</td>\n",
       "      <td>40.710880</td>\n",
       "      <td>East Williamsburg</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>POLYGON ((1003166.891 204533.535, 1003184.978 ...</td>\n",
       "      <td>POINT (3741691.522 1227177.753)</td>\n",
       "      <td>-73.936794</td>\n",
       "      <td>40.715370</td>\n",
       "      <td>2.015894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-02-01 00:56:05</td>\n",
       "      <td>2018-02-01 01:18:54</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>95</td>\n",
       "      <td>1</td>\n",
       "      <td>9.60</td>\n",
       "      <td>28.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5.96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>35.76</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Boerum Hill</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>POLYGON ((989365.837 190351.505, 989514.254 19...</td>\n",
       "      <td>POINT (3739545.196 1222312.090)</td>\n",
       "      <td>-73.986114</td>\n",
       "      <td>40.685634</td>\n",
       "      <td>Forest Hills</td>\n",
       "      <td>Queens</td>\n",
       "      <td>POLYGON ((1026559.225 208467.841, 1026590.157 ...</td>\n",
       "      <td>POINT (3748035.762 1231293.081)</td>\n",
       "      <td>-73.847669</td>\n",
       "      <td>40.721432</td>\n",
       "      <td>12.359122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-02-01 00:12:40</td>\n",
       "      <td>2018-02-01 00:15:50</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>61</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>0.73</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>5.80</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Crown Heights North</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>POLYGON ((1003897.089 188278.650, 1003939.593 ...</td>\n",
       "      <td>POINT (3743625.521 1223063.877)</td>\n",
       "      <td>-73.939287</td>\n",
       "      <td>40.674470</td>\n",
       "      <td>Crown Heights North</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>POLYGON ((1003897.089 188278.650, 1003939.593 ...</td>\n",
       "      <td>POINT (3743625.521 1223063.877)</td>\n",
       "      <td>-73.939287</td>\n",
       "      <td>40.674470</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-02-01 00:45:18</td>\n",
       "      <td>2018-02-01 00:51:56</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>1.87</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>9.30</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Downtown Brooklyn/MetroTech</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>POLYGON ((987819.980 194536.761, 987838.631 19...</td>\n",
       "      <td>POINT (3739044.681 1223266.137)</td>\n",
       "      <td>-73.986086</td>\n",
       "      <td>40.695337</td>\n",
       "      <td>Bedford</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>POLYGON ((1000036.904 194829.434, 1000276.454 ...</td>\n",
       "      <td>POINT (3741948.436 1224317.470)</td>\n",
       "      <td>-73.949905</td>\n",
       "      <td>40.691507</td>\n",
       "      <td>3.088219</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VendorID lpep_pickup_datetime lpep_dropoff_datetime store_and_fwd_flag  \\\n",
       "0         2  2018-02-01 00:39:38   2018-02-01 00:39:41                  N   \n",
       "1         2  2018-02-01 00:58:28   2018-02-01 01:05:35                  N   \n",
       "2         2  2018-02-01 00:56:05   2018-02-01 01:18:54                  N   \n",
       "3         2  2018-02-01 00:12:40   2018-02-01 00:15:50                  N   \n",
       "4         2  2018-02-01 00:45:18   2018-02-01 00:51:56                  N   \n",
       "\n",
       "   RatecodeID  PULocationID  DOLocationID  passenger_count  trip_distance  \\\n",
       "0           5            97            65                1           0.00   \n",
       "1           1           256            80                5           1.60   \n",
       "2           1            25            95                1           9.60   \n",
       "3           1            61            61                1           0.73   \n",
       "4           1            65            17                2           1.87   \n",
       "\n",
       "   fare_amount  extra  mta_tax  tip_amount  tolls_amount  ehail_fee  \\\n",
       "0         20.0    0.0      0.0        3.00           0.0        NaN   \n",
       "1          7.5    0.5      0.5        0.88           0.0        NaN   \n",
       "2         28.5    0.5      0.5        5.96           0.0        NaN   \n",
       "3          4.5    0.5      0.5        0.00           0.0        NaN   \n",
       "4          8.0    0.5      0.5        0.00           0.0        NaN   \n",
       "\n",
       "   improvement_surcharge  total_amount  payment_type  trip_type  \\\n",
       "0                    0.0         23.00             1          2   \n",
       "1                    0.3          9.68             1          1   \n",
       "2                    0.3         35.76             1          1   \n",
       "3                    0.3          5.80             2          1   \n",
       "4                    0.3          9.30             2          1   \n",
       "\n",
       "                       zone_PU borough_PU  \\\n",
       "0                  Fort Greene   Brooklyn   \n",
       "1    Williamsburg (South Side)   Brooklyn   \n",
       "2                  Boerum Hill   Brooklyn   \n",
       "3          Crown Heights North   Brooklyn   \n",
       "4  Downtown Brooklyn/MetroTech   Brooklyn   \n",
       "\n",
       "                                         geometry_PU  \\\n",
       "0  POLYGON ((992751.699 192765.140, 992899.310 19...   \n",
       "1  POLYGON ((995798.638 199155.970, 996223.601 19...   \n",
       "2  POLYGON ((989365.837 190351.505, 989514.254 19...   \n",
       "3  POLYGON ((1003897.089 188278.650, 1003939.593 ...   \n",
       "4  POLYGON ((987819.980 194536.761, 987838.631 19...   \n",
       "\n",
       "                       centroid_PU  latitude_PU  longitude_PU  \\\n",
       "0  POINT (3740118.202 1223261.158)   -73.974882     40.690787   \n",
       "1  POINT (3740196.862 1225825.044)   -73.959905     40.710880   \n",
       "2  POINT (3739545.196 1222312.090)   -73.986114     40.685634   \n",
       "3  POINT (3743625.521 1223063.877)   -73.939287     40.674470   \n",
       "4  POINT (3739044.681 1223266.137)   -73.986086     40.695337   \n",
       "\n",
       "                       zone_DO borough_DO  \\\n",
       "0  Downtown Brooklyn/MetroTech   Brooklyn   \n",
       "1            East Williamsburg   Brooklyn   \n",
       "2                 Forest Hills     Queens   \n",
       "3          Crown Heights North   Brooklyn   \n",
       "4                      Bedford   Brooklyn   \n",
       "\n",
       "                                         geometry_DO  \\\n",
       "0  POLYGON ((987819.980 194536.761, 987838.631 19...   \n",
       "1  POLYGON ((1003166.891 204533.535, 1003184.978 ...   \n",
       "2  POLYGON ((1026559.225 208467.841, 1026590.157 ...   \n",
       "3  POLYGON ((1003897.089 188278.650, 1003939.593 ...   \n",
       "4  POLYGON ((1000036.904 194829.434, 1000276.454 ...   \n",
       "\n",
       "                       centroid_DO  latitude_DO  longitude_DO  geo_distance  \n",
       "0  POINT (3739044.681 1223266.137)   -73.986086     40.695337      1.073533  \n",
       "1  POINT (3741691.522 1227177.753)   -73.936794     40.715370      2.015894  \n",
       "2  POINT (3748035.762 1231293.081)   -73.847669     40.721432     12.359122  \n",
       "3  POINT (3743625.521 1223063.877)   -73.939287     40.674470      0.000000  \n",
       "4  POINT (3741948.436 1224317.470)   -73.949905     40.691507      3.088219  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option(\"display.max_columns\", None)\n",
    "trip_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add datetime parts based on pickup time and duration to validate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_df[\"hour\"] = trip_df.lpep_pickup_datetime.dt.hour\n",
    "trip_df[\"weekday\"] = trip_df.lpep_pickup_datetime.dt.weekday\n",
    "trip_df[\"month\"] = trip_df.lpep_pickup_datetime.dt.month\n",
    "trip_df[\"duration_minutes\"] = (\n",
    "    trip_df[\"lpep_dropoff_datetime\"] - trip_df[\"lpep_pickup_datetime\"]\n",
    ").dt.seconds / 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data visualization\n",
    "\n",
    "Let's check that we have a good spread of travel across each day of the week and hour of the day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.histplot(trip_df, x=\"hour\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And plot that we have a distribution across week days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(trip_df, x=\"weekday\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's validate that the geo distance correlations generally with the fare amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = trip_df[trip_df[\"geo_distance\"] > 0].sample(1000)\n",
    "sns.jointplot(data=sample_df, x=\"geo_distance\", y=\"fare_amount\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the geometry of the map along with centroids for each location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import LineString\n",
    "\n",
    "\n",
    "def annotate(ax, z):\n",
    "    txt = f\"{z.name}: {z.zone} ({-z.latitude:.2f}°N, {z.longitude:.2f}°W)\"\n",
    "    ax.annotate(txt, (z.latitude, z.longitude))\n",
    "\n",
    "\n",
    "def arrow(ax, ll):\n",
    "    ld = ll.iloc[1] - ll.iloc[0]\n",
    "    ax.arrow(\n",
    "        ll.iloc[0].latitude,\n",
    "        ll.iloc[0].longitude,\n",
    "        ld.latitude,\n",
    "        ld.longitude,\n",
    "        length_includes_head=True,\n",
    "        edgecolor=\"lightgrey\",\n",
    "    )\n",
    "\n",
    "\n",
    "def plot_map(zones, zids):\n",
    "    # Render the geometry in Lat/Lon space\n",
    "    ax = zones.geometry.to_crs(epsg=4326).plot(\n",
    "        figsize=(15, 15), color=\"whitesmoke\", edgecolor=\"lightgrey\", linewidth=0.5\n",
    "    )\n",
    "    # Draw arrow\n",
    "    arrow(ax, zones.loc[zids][[\"latitude\", \"longitude\"]])\n",
    "    # Plot centroid\n",
    "    centroids = zones.loc[zids].geometry.centroid.to_crs(\n",
    "        epsg=3310\n",
    "    )  # Require this format for calculating distance\n",
    "    centroids.to_crs(epsg=4326).plot(ax=ax, color=\"red\", marker=\"+\")\n",
    "    # Annotate points\n",
    "    for i, row in zones.loc[zids].iterrows():\n",
    "        annotate(ax, row)\n",
    "    # Output the distance traveled\n",
    "    dist = centroids.iloc[0].distance(centroids.iloc[1]) / 1000\n",
    "    plt.title(f\"From zone {zids[0]} to {zids[1]} distance: {dist:.2f}km\")\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select a trip to inspect the zones it travels from and to and the duration and cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_idx = 5\n",
    "\n",
    "# Get the trip and plot on map\n",
    "t = trip_df.iloc[trip_idx]\n",
    "dist = plot_map(zones, [t.PULocationID, t.DOLocationID])\n",
    "\n",
    "print(\n",
    "    f\"Took {t.duration_minutes:.2f} minutes on {t.weekday} at {t.hour} hour to travel {dist:.2f}km for the cost of ${t.fare_amount:.2f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename and select columns that we want build model on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename cols\n",
    "trip_df = trip_df.rename(\n",
    "    columns={\n",
    "        \"latitude_PU\": \"pickup_latitude\",\n",
    "        \"longitude_PU\": \"pickup_longitude\",\n",
    "        \"latitude_DO\": \"dropoff_latitude\",\n",
    "        \"longitude_DO\": \"dropoff_longitude\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# Select cols\n",
    "cols = [\n",
    "    \"fare_amount\",\n",
    "    \"pickup_latitude\",\n",
    "    \"pickup_longitude\",\n",
    "    \"dropoff_latitude\",\n",
    "    \"dropoff_longitude\",\n",
    "    \"geo_distance\",\n",
    "    \"hour\",\n",
    "    \"weekday\",\n",
    "    \"month\",\n",
    "]\n",
    "data_df = trip_df[cols]\n",
    "data_df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean up to remove some outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = data_df[\n",
    "    (data_df.fare_amount > 0)\n",
    "    & (data_df.fare_amount < 200)\n",
    "    & (data_df.geo_distance >= 0)\n",
    "    & (data_df.geo_distance < 121)\n",
    "].dropna()\n",
    "print(data_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data splitting and saving\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to split the dataset into train, validation, and test sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, val_df = train_test_split(data_df, test_size=0.20, random_state=42)\n",
    "val_df, test_df = train_test_split(val_df, test_size=0.05, random_state=42)\n",
    "\n",
    "# Reset the index for our test dataframe\n",
    "test_df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "print(\n",
    "    \"Size of\\n train: {},\\n val: {},\\n test: {} \".format(\n",
    "        train_df.shape[0], val_df.shape[0], test_df.shape[0]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the train, validation, and test files as CSV locally on this notebook instance. Notice that you save the train file twice - once as the training data file and once as the baseline data file. The baseline data file will be used by [SageMaker Model Monitor](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor.html)⇗ to detect data drift. Data drift occurs when the statistical nature of the data that your model receives while in production drifts away from the nature of the baseline data it was trained on, which means the model begins to lose accuracy in its predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(\"train.csv\", index=False, header=False)\n",
    "val_df.to_csv(\"validation.csv\", index=False, header=False)\n",
    "test_df.to_csv(\"test.csv\", index=False, header=False)\n",
    "\n",
    "# Save test and baseline with headers\n",
    "train_df.to_csv(\"baseline.csv\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now upload these CSV files to your default SageMaker S3 bucket. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "# Get the session and default bucket\n",
    "session = sagemaker.session.Session()\n",
    "bucket = session.default_bucket()\n",
    "\n",
    "# Specify data prefix and version\n",
    "prefix = \"nyc-tlc/v2\"\n",
    "\n",
    "s3_train_uri = session.upload_data(\"train.csv\", bucket, prefix + \"/data/training\")\n",
    "s3_val_uri = session.upload_data(\"validation.csv\", bucket, prefix + \"/data/validation\")\n",
    "s3_test_uri = session.upload_data(\"test.csv\", bucket, prefix + \"/data/test\")\n",
    "s3_baseline_uri = session.upload_data(\"baseline.csv\", bucket, prefix + \"/data/baseline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Job\n",
    "\n",
    "Build an estimator to train on this, see if using geo_distance its okay predictor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Can XGBoost report use a version which accepts the header for feature importance?\n",
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.debugger import Rule, rule_configs\n",
    "\n",
    "# Get role and region\n",
    "role = sagemaker.get_execution_role()\n",
    "region = sagemaker.session.Session().boto_session.region_name\n",
    "\n",
    "# Define the XGBoost training report rules\n",
    "# see: https://docs.aws.amazon.com/sagemaker/latest/dg/debugger-training-xgboost-report.html\n",
    "rules = [Rule.sagemaker(rule_configs.create_xgboost_report())]\n",
    "\n",
    "# Get the training instance type\n",
    "training_instance_type = \"ml.m4.xlarge\"\n",
    "\n",
    "# training step for generating model artifacts\n",
    "image_uri = sagemaker.image_uris.retrieve(\n",
    "    framework=\"xgboost\",\n",
    "    region=region,\n",
    "    version=\"1.2-2\",\n",
    "    py_version=\"py3\",\n",
    "    instance_type=training_instance_type,\n",
    ")\n",
    "\n",
    "output_path = \"s3://{}/{}/output\".format(bucket, prefix)\n",
    "\n",
    "estimator = Estimator(\n",
    "    image_uri=image_uri,\n",
    "    instance_type=training_instance_type,\n",
    "    instance_count=1,\n",
    "    output_path=output_path,\n",
    "    role=role,\n",
    "    disable_profiler=True,  # Profile processing job\n",
    "    rules=rules,  # Report processing job\n",
    ")\n",
    "\n",
    "hp = {\n",
    "    \"max_depth\": \"9\",\n",
    "    \"eta\": \"0.2\",\n",
    "    \"gamma\": \"4\",\n",
    "    \"min_child_weight\": \"300\",\n",
    "    \"subsample\": \"0.8\",\n",
    "    \"objective\": \"reg:squarederror\",  # reg:linear not supported\n",
    "    \"early_stopping_rounds\": \"10\",\n",
    "    \"num_round\": \"100\",\n",
    "}\n",
    "estimator.set_hyperparameters(**hp)\n",
    "\n",
    "# Set the data\n",
    "s3_input_train = sagemaker.inputs.TrainingInput(\n",
    "    s3_data=s3_train_uri, content_type=\"text/csv\"\n",
    ")\n",
    "s3_input_val = sagemaker.inputs.TrainingInput(\n",
    "    s3_data=s3_val_uri, content_type=\"text/csv\"\n",
    ")\n",
    "data = {\"train\": s3_input_train, \"validation\": s3_input_val}\n",
    "\n",
    "estimator.fit(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate \n",
    "\n",
    "Wait for the XGBoost report to be ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_client = sagemaker.session.Session().sagemaker_client\n",
    "\n",
    "# Attach the job and get report\n",
    "xgb_report_job_name = [\n",
    "    rule[\"RuleEvaluationJobArn\"].split(\"/\")[-1]\n",
    "    for rule in estimator.latest_training_job.rule_job_summary()\n",
    "    if \"CreateXgboostReport\" in rule[\"RuleConfigurationName\"]\n",
    "][0]\n",
    "\n",
    "print(f\"Waiting for XGBoost training report {xgb_report_job_name} to complete...\")\n",
    "sm_client.get_waiter(\"processing_job_completed_or_stopped\").wait(\n",
    "    ProcessingJobName=xgb_report_job_name\n",
    ")\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspects the results of the report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import FileLink\n",
    "from sagemaker.s3 import S3Downloader, S3Uploader\n",
    "\n",
    "# Get the s3 output\n",
    "report_uri = sm_client.describe_processing_job(ProcessingJobName=xgb_report_job_name)[\n",
    "    \"ProcessingOutputConfig\"\n",
    "][\"Outputs\"][0][\"S3Output\"][\"S3Uri\"]\n",
    "\n",
    "# Download the notebook from the report\n",
    "S3Downloader().download(f\"{report_uri}/xgboost_report.html\", \"report\")\n",
    "FileLink(\"report/xgboost_report.html\", result_html_prefix=\"Open Report: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy\n",
    "\n",
    "Deploy an endpoint for the predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.serializers import CSVSerializer\n",
    "from sagemaker.deserializers import CSVDeserializer\n",
    "\n",
    "predictor = estimator.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.m4.xlarge\",\n",
    "    serializer=CSVSerializer(),\n",
    "    deserializer=CSVDeserializer(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get predictions for the held out test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunker(seq, batch_size):\n",
    "    return (seq[pos : pos + batch_size] for pos in range(0, len(seq), batch_size))\n",
    "\n",
    "\n",
    "# Make predictions without the first colunns\n",
    "results = []\n",
    "for df in chunker(test_df[test_df.columns[1:]], 20):\n",
    "    results += predictor.predict(data=df.to_csv(index=False, header=False))[0]\n",
    "\n",
    "# Get the fare amoiunt pred back in the dataframe\\\n",
    "predictions = pd.Series(results).astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join the predictions back to the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame({\"fare_amount_prediction\": predictions})\n",
    "pred_df = test_df.join(pred_df)\n",
    "\n",
    "# Get abs error\n",
    "pred_df[\"error\"] = abs(pred_df[\"fare_amount\"] - pred_df[\"fare_amount_prediction\"])\n",
    "pred_df.sort_values(\"error\", ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the root mean squre error (RMSE) to evaluate the performance of this model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "def rmse(pred_df):\n",
    "    return sqrt(\n",
    "        mean_squared_error(pred_df[\"fare_amount\"], pred_df[\"fare_amount_prediction\"])\n",
    "    )\n",
    "\n",
    "\n",
    "print(\"RMSE: {}\".format(rmse(pred_df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the residules to see where the errors are relative to the fare amount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.residplot(\n",
    "    x=pred_df[\"fare_amount\"], y=pred_df[\"fare_amount_prediction\"], lowess=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "interpreter": {
   "hash": "07c1d6c68b7b22b50965762993b154aa5a1dd6aa65a365988d7d4c27c573599b"
  },
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
